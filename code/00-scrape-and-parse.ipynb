{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdc62e0-004a-4d5a-99b7-fa7eb7f155ef",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Part 0: Scraping and Parsing\n",
    "\n",
    "This section will illustrate the process of scraping and parsing Reddit that I performed for this project.\n",
    "\n",
    "Most scraping and parsing was done using two custom-made scripts, `scraper.py` and `parser.py`, located in the code directory. These scripts export the following classes:\n",
    "\n",
    "`RedditReader`: A class for scraping Reddit using selenium. Because Reddit loads its post data dynamically in chunks, it was required to emulate a human user and scroll down the page as far as necessary to scrape the posts. The goal here was to avoid use of a much easier-to-use API.\n",
    "\n",
    "`RedditParser`: A class for parsing the Reddit page source for the necessary information.\n",
    "\n",
    "The `scraper.py` module uses the following third-party packages:\n",
    "\n",
    "- `selenium` (requires Chrome as ChromeDriver is hardcoded in the script for now)\n",
    "\n",
    "The `parser.py` modules uses the following third-party packages:\n",
    "\n",
    "- `bs4`\n",
    "\n",
    "The actual scraping done for this project was performed in ipython and the command line. I will replicate my steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e88e1-2f54-4d2b-9945-6686167c5085",
   "metadata": {},
   "source": [
    "### 0. Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ea92b9-97ab-4040-9ac8-5d97825c1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from scraper import RedditReader\n",
    "from parser import RedditParser\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083e8ca-ba0a-44b3-b3c4-a845e8d133aa",
   "metadata": {},
   "source": [
    "### 1. Scraping\n",
    "\n",
    "**Note:** The code in this section will run an example scrape using the `scraper.py` module. As previously mentioned, the actual scraping was performed from the command line and in ipython. My executable code to automate this is located at the bottom of `scraper.py` and in the `multiscraper.py` script.\n",
    "\n",
    "The below code is commented out to prevent possible errors due to configuration (see above). Remove markdown code quotes and convert to code cell to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8327a-8d4c-43bf-b6b5-fb61bc8380bc",
   "metadata": {},
   "source": [
    "```python\n",
    "number_of_scrolls = 10 # adjust to taste\n",
    "\n",
    "with RedditReader() as rr:\n",
    "    rr.set_sleep_time(4) # give time for page load\n",
    "    \n",
    "    # get URL\n",
    "    rr.get() # automatically sleeps for above time\n",
    "    rr.set_sleep_time(8) # give time for scrolling\n",
    "    \n",
    "    for i in range(number_of_scrolls):\n",
    "        # scroll page 10 times to get a subset of data\n",
    "        rr.scroll() # automatically scrolls to bottom of scrollable area\n",
    "        \n",
    "    # done with scrolling - write to disk\n",
    "    rr.write_page_source() # by default timestamps file and writes to scraped dir\n",
    "    \n",
    "    # selenium is automatically closed by virtue of the 'with' call\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4876f8-1a7f-42b3-a02e-9d8e72f290f0",
   "metadata": {},
   "source": [
    "### 2. Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1def14c-b837-43a7-a9ac-9f6f6d3eecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scrape_20220905_210656.txt', 'search', 'scrape_20220905_204314.txt', 'scrape_20220830_172503.txt', 'page']\n"
     ]
    }
   ],
   "source": [
    "# get main subreddit scrapes\n",
    "scrape_dir = '../scrapes/'\n",
    "scrape_files = os.listdir(scrape_dir)\n",
    "print(scrape_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efba04df-cba5-4780-8fd8-713bc6471cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed ../scrapes/scrape_20220905_210656.txt\n",
      "processed ../scrapes/scrape_20220905_204314.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# process contents using custom script (see above)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# file is read as part of class instantiation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m rp \u001b[38;5;241m=\u001b[39m RedditParser(scrape_dir \u001b[38;5;241m+\u001b[39m file)\n\u001b[0;32m----> 8\u001b[0m info\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m scrape_dir \u001b[38;5;241m+\u001b[39m file)\n",
      "File \u001b[0;32m~/proj/GA/repos/project_3/code/parser.py:59\u001b[0m, in \u001b[0;36mRedditParser.go\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# put all content into results dictionary\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_content(\u001b[38;5;28mtype\u001b[39m, post)\n\u001b[1;32m     60\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m posts]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_len_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_[types[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# make a derived ID for each post\u001b[39;00m\n",
      "File \u001b[0;32m~/proj/GA/repos/project_3/code/parser.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# put all content into results dictionary\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m posts]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_len_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_[types[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# make a derived ID for each post\u001b[39;00m\n",
      "File \u001b[0;32m~/proj/GA/repos/project_3/code/parser.py:108\u001b[0m, in \u001b[0;36mRedditParser.get_content\u001b[0;34m(self, type, container)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# process text\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(\u001b[38;5;28mtype\u001b[39m, \u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/bs4/element.py:293\u001b[0m, in \u001b[0;36mPageElement.get_text\u001b[0;34m(self, separator, strip, types)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m              types\u001b[38;5;241m=\u001b[39mdefault):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Get all child strings of this PageElement, concatenated using the\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    given separator.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :return: A string.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m separator\u001b[38;5;241m.\u001b[39mjoin([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_strings(\n\u001b[1;32m    294\u001b[0m                 strip, types\u001b[38;5;241m=\u001b[39mtypes)])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/bs4/element.py:293\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m              types\u001b[38;5;241m=\u001b[39mdefault):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Get all child strings of this PageElement, concatenated using the\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    given separator.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :return: A string.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m separator\u001b[38;5;241m.\u001b[39mjoin([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_strings(\n\u001b[1;32m    294\u001b[0m                 strip, types\u001b[38;5;241m=\u001b[39mtypes)])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/bs4/element.py:1383\u001b[0m, in \u001b[0;36mTag._all_strings\u001b[0;34m(self, strip, types)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[1;32m   1381\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteresting_string_types\n\u001b[0;32m-> 1383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m descendant \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescendants:\n\u001b[1;32m   1384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(descendant, NavigableString)):\n\u001b[1;32m   1385\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/bs4/element.py:1915\u001b[0m, in \u001b[0;36mTag.descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontents):\n\u001b[1;32m   1914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1915\u001b[0m stopNode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_descendant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnext_element\n\u001b[1;32m   1916\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stopNode:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/bs4/element.py:399\u001b[0m, in \u001b[0;36mPageElement._last_descendant\u001b[0;34m(self, is_initialized, accept_self)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     last_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(last_child, Tag) \u001b[38;5;129;01mand\u001b[39;00m last_child\u001b[38;5;241m.\u001b[39mcontents:\n\u001b[1;32m    400\u001b[0m         last_child \u001b[38;5;241m=\u001b[39m last_child\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accept_self \u001b[38;5;129;01mand\u001b[39;00m last_child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for each scrape, parse and collect relevant data, then add to a list\n",
    "info = list()\n",
    "for file in scrape_files:\n",
    "    if not file.endswith('.txt'): continue\n",
    "    # process contents using custom script (see above)\n",
    "    # file is read as part of class instantiation\n",
    "    rp = RedditParser(scrape_dir + file)\n",
    "    info.append(rp.go())\n",
    "    print(f'processed ' + scrape_dir + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091c36b-211e-48b3-b155-405b29773a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict/arrays to dataframes and concat to a single big dataframe\n",
    "container_df = pd.DataFrame()\n",
    "\n",
    "for ix, v in enumerate(info):\n",
    "    container_df = pd.concat([container_df, pd.DataFrame(v)])\n",
    "    print(f'converted {str(ix)} of {len(info)}')\n",
    "\n",
    "# drop duplicate rows (determined by uid created as part of the parser)\n",
    "df = container_df.drop_duplicates('uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21daa2a1-9948-4970-a1e5-8c5eb33a339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unused variables to save memory\n",
    "del info\n",
    "del container_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101bb97-25a0-4a10-98ae-b6929dae116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have additional post scrapes to parse\n",
    "post_scrape_dir = scrape_dir + 'page/'\n",
    "post_scrape_files = os.listdir(post_scrape_dir)\n",
    "print(post_scrape_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916af7da-4046-4003-884a-829a01fd3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape each post\n",
    "info = list()\n",
    "count = 0\n",
    "for file in post_scrape_files:\n",
    "    rp = RedditParser(post_scrape_dir + file, tags_file='tags_post.json')\n",
    "    info.append(rp.go())\n",
    "    count += 1\n",
    "    #print(f'processed {post_scrape_dir}{file}')\n",
    "    if not count % 50: print('.', end='') # 7k+ files - shorten output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd497297-868b-4bd8-a7ae-ec320c0dc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for ix, v in enumerate(info):\n",
    "    container_df = pd.concat([container_df, pd.DataFrame(v)])\n",
    "    count += 1\n",
    "    #print(f'converted {str(ix)} of {len(info)}')\n",
    "    if not count % 50: print('.', end='') # shorten output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37031fef-2276-40d0-8448-248aec65ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311935f-a495-425a-a7f5-0b75c20f47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3f50fb-3ce2-45e8-b2bb-9e59fdd7b272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8718, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all rows\n",
    "df = pd.concat([df, container_df]).drop_duplicates('uid')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbea19a-a680-44d1-8d94-a6601f77a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FOR A DROP DUPLICATE TITLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a002f8f-edef-435b-90fc-e5400e0ce0de",
   "metadata": {},
   "source": [
    "# 3. Verify and Write To Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189dc60f-3e28-43cc-9b69-34e30f1487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e10f34a-15e1-4a26-8777-4da77d5293ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8718, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9091c017-741a-40d0-9bac-7d886fade0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>comments</th>\n",
       "      <th>body-text</th>\n",
       "      <th>media</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newbie questions about ascendants and borders</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm new to actually learning astrology, not ju...</td>\n",
       "      <td></td>\n",
       "      <td>45Newbiequestionsaboutascendantsandborders601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thousands of uncharted planets at your fingert...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>100Thousandsofunchartedplanetsatyourfingertips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astrology and cognitive dissonance</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>Open to anyone who wouldn't mind sharing a rec...</td>\n",
       "      <td></td>\n",
       "      <td>34Astrologyandcognitivedissonance323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what do y’all think of persona charts?</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel a bit skeptical of them, since I feel l...</td>\n",
       "      <td></td>\n",
       "      <td>38whatdoy’allthinkofpersonacharts?180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESOURCE REQUEST: Videos (or articles) with ti...</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>2</td>\n",
       "      <td>I think my problem is that I don’t know the pr...</td>\n",
       "      <td></td>\n",
       "      <td>160RESOURCEREQUEST:Videos(orarticles)withtips/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        time  comments  \\\n",
       "0      Newbie questions about ascendants and borders  2022-09-05         0   \n",
       "1  Thousands of uncharted planets at your fingert...                     0   \n",
       "2                 Astrology and cognitive dissonance  2022-09-05         1   \n",
       "3             what do y’all think of persona charts?  2022-09-05         0   \n",
       "4  RESOURCE REQUEST: Videos (or articles) with ti...  2022-09-05         2   \n",
       "\n",
       "                                           body-text media  \\\n",
       "0  I'm new to actually learning astrology, not ju...         \n",
       "1                                                     True   \n",
       "2  Open to anyone who wouldn't mind sharing a rec...         \n",
       "3  I feel a bit skeptical of them, since I feel l...         \n",
       "4  I think my problem is that I don’t know the pr...         \n",
       "\n",
       "                                                 uid  \n",
       "0      45Newbiequestionsaboutascendantsandborders601  \n",
       "1  100Thousandsofunchartedplanetsatyourfingertips...  \n",
       "2               34Astrologyandcognitivedissonance323  \n",
       "3              38whatdoy’allthinkofpersonacharts?180  \n",
       "4  160RESOURCEREQUEST:Videos(orarticles)withtips/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check general look of table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa7c177-44f0-4915-8fb2-e2d939945d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45Newbiequestionsaboutascendantsandborders601</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Newbie questions about ascendants and borders</td>\n",
       "      <td>I'm new to actually learning astrology, not ju...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100Thousandsofunchartedplanetsatyourfingertips...</td>\n",
       "      <td></td>\n",
       "      <td>Thousands of uncharted planets at your fingert...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34Astrologyandcognitivedissonance323</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Astrology and cognitive dissonance</td>\n",
       "      <td>Open to anyone who wouldn't mind sharing a rec...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38whatdoy’allthinkofpersonacharts?180</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>what do y’all think of persona charts?</td>\n",
       "      <td>I feel a bit skeptical of them, since I feel l...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160RESOURCEREQUEST:Videos(orarticles)withtips/...</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>RESOURCE REQUEST: Videos (or articles) with ti...</td>\n",
       "      <td>I think my problem is that I don’t know the pr...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uid        time  \\\n",
       "0      45Newbiequestionsaboutascendantsandborders601  2022-09-05   \n",
       "1  100Thousandsofunchartedplanetsatyourfingertips...               \n",
       "2               34Astrologyandcognitivedissonance323  2022-09-05   \n",
       "3              38whatdoy’allthinkofpersonacharts?180  2022-09-05   \n",
       "4  160RESOURCEREQUEST:Videos(orarticles)withtips/...  2022-09-05   \n",
       "\n",
       "                                               title  \\\n",
       "0      Newbie questions about ascendants and borders   \n",
       "1  Thousands of uncharted planets at your fingert...   \n",
       "2                 Astrology and cognitive dissonance   \n",
       "3             what do y’all think of persona charts?   \n",
       "4  RESOURCE REQUEST: Videos (or articles) with ti...   \n",
       "\n",
       "                                           body-text media  comments  \n",
       "0  I'm new to actually learning astrology, not ju...               0  \n",
       "1                                                     True         0  \n",
       "2  Open to anyone who wouldn't mind sharing a rec...               1  \n",
       "3  I feel a bit skeptical of them, since I feel l...               0  \n",
       "4  I think my problem is that I don’t know the pr...               2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rearrange columns\n",
    "df = df[['uid','time','title','body-text','media','comments']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ed319e1-1c06-4b61-bad3-ccffac21b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will export to json here because that seems more intuitive to me for this\n",
    "# kind of long string data\n",
    "df.to_json('../data/scrapes.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db78c8e9-b919-492a-b1d3-eb9b22dab61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
