{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e635b4-7f51-4771-b503-3991eb4065e4",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Part 2: Modeling\n",
    "\n",
    "Model data for fun and profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99841833-554e-40b2-b472-4a57b0cf38be",
   "metadata": {},
   "source": [
    "### 0. Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50529b0d-9aea-49b6-9429-7f6b910de60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# pipelines, gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# custom\n",
    "import ipynb_utils as ipyutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96d9fe-61c8-4b4e-8909-50c00610ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_json('../data/scrapes-clean.json', orient='index')\n",
    "\n",
    "# convert time to datetime object\n",
    "df['time'] = pd.to_datetime(df['time'], format=ipyutils.DATE_FMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6020c18d-2747-4806-bdfd-94cdda105993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>Saturn Return MEGATHREAD - we've been getting ...</td>\n",
       "      <td></td>\n",
       "      <td>214</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>MERCURY RX INFOGRAPHIC: Taurus/Gemini, Apr-Jun...</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>CHANI app issues?</td>\n",
       "      <td>I just downloaded the CHANI app to try out and...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>221</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>Is Mercury in Aquarius in the 6th House as pow...</td>\n",
       "      <td>Not new to the deeper parts of astrology but t...</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>314</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>What is the proper orb for a sextile?</td>\n",
       "      <td>What is the proper and respective orb for a se...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title  \\\n",
       "0 2022-02-01  Saturn Return MEGATHREAD - we've been getting ...   \n",
       "1 2022-06-01  MERCURY RX INFOGRAPHIC: Taurus/Gemini, Apr-Jun...   \n",
       "2 2022-08-30                                  CHANI app issues?   \n",
       "4 2022-08-30  Is Mercury in Aquarius in the 6th House as pow...   \n",
       "5 2022-08-30              What is the proper orb for a sextile?   \n",
       "\n",
       "                                           body-text  title-cc  title-wc  \\\n",
       "0                                                          214        35   \n",
       "1                                                           51         8   \n",
       "2  I just downloaded the CHANI app to try out and...        17         3   \n",
       "4  Not new to the deeper parts of astrology but t...        86        17   \n",
       "5  What is the proper and respective orb for a se...        37         7   \n",
       "\n",
       "   body-cc  body-wc  media  comments  \n",
       "0        0        0      0       330  \n",
       "1        0        0      0        22  \n",
       "2      221       40      0         4  \n",
       "4      314       56      0         8  \n",
       "5      224       42      0         8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all looks good...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68d3abe-7eda-4afc-aad8-c0fb1bdc3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         datetime64[ns]\n",
       "title                object\n",
       "body-text            object\n",
       "title-cc              int64\n",
       "title-wc              int64\n",
       "body-cc               int64\n",
       "body-wc               int64\n",
       "media                 int64\n",
       "comments              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and that the right datatypes are showing\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ea98a-32ed-4d4f-9d19-1524ee3836ae",
   "metadata": {},
   "source": [
    "### 0.5. Problem Statement\n",
    "\n",
    "What characteristics of a post on Reddit are most predictive of the overall interaction on a thread (as measured by number of comments)?\n",
    "\n",
    "Model will predict whether or not a given Reddit post will have above or below the median number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa388c-79f9-48bd-bb58-3b48e0aa7a62",
   "metadata": {},
   "source": [
    "### 1. Generate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50e06b6-908f-48bf-9da0-45e59538381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median comments\n",
    "median = np.median(df['comments'])\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb5882c-281f-4590-87a3-9d02cd06c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    993\n",
       "1    979\n",
       "Name: comments_gt_median, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target column\n",
    "df['comments_gt_median'] = (df['comments'] > median).astype(int)\n",
    "df['comments_gt_median'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4b475-21fc-492b-8192-0e8fb9e2e5e9",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "Baseline is just about **50%** (we are using median)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff91f72-3c70-4c85-a04c-404b0cf25365",
   "metadata": {},
   "source": [
    "### 1a. Split Time Column\n",
    "\n",
    "Might want to check by month or day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff00a030-b964-4f6f-86b7-2dc6be418e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['time'].apply(ipyutils.get_day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113fea0d-7c35-450b-9f5c-380b93291297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['time'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59e1340-568b-48d4-a6e8-30601e41c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month\n",
       "0    1      2\n",
       "1    2      6\n",
       "2    1      8\n",
       "4    1      8\n",
       "5    1      8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['day','month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec924ed-83a8-4c00-9193-0a2add1b6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     1\n",
       "8     1\n",
       "10    1\n",
       "11    1\n",
       "Name: weekend, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekend'] = (df['day'] > 5).astype(int)\n",
    "df['weekend'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cb886e1-140e-4947-8eb2-2affc76f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this just to be safe as I've gotten some weird row mismatches\n",
    "# later on and not sure exactly why\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421586c-0e19-4b86-8f58-b8ebdd3d751c",
   "metadata": {},
   "source": [
    "### 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2ff9ecee-a22a-42de-bba7-c90e944b8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1577, 11), (395, 11), (1577,), (395,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = 'comments_gt_median'\n",
    "cols_to_drop = ['time'] # don't need this any more\n",
    "X = df.drop(columns=[col_target]+cols_to_drop)\n",
    "y = df[col_target]\n",
    "\n",
    "# split to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20637c-93dd-4710-aa9f-36f5ab8d8867",
   "metadata": {},
   "source": [
    "### 3. Count Vectorize Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8f5ffad-24f9-4d37-8311-791f9d141dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1577, 1276),\n",
       " (1577, 4416),\n",
       " (395, 1276),\n",
       " (395, 4416),\n",
       " (1577, 4782),\n",
       " (395, 4782))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count vectorize tables\n",
    "cv_min_df = 2\n",
    "title_cv = CountVectorizer(token_pattern=ipyutils.PAT_TOKEN, min_df=cv_min_df)\n",
    "body_cv = CountVectorizer(token_pattern=ipyutils.PAT_TOKEN, min_df=cv_min_df)\n",
    "alltext_cv = CountVectorizer(token_pattern=ipyutils.PAT_TOKEN, min_df=cv_min_df)\n",
    "\n",
    "# title\n",
    "train_title_cv = title_cv.fit_transform(X_train['title'])\n",
    "test_title_cv = title_cv.transform(X_test['title'])\n",
    "\n",
    "# body\n",
    "train_body_cv = body_cv.fit_transform(X_train['body-text'])\n",
    "test_body_cv = body_cv.transform(X_test['body-text'])\n",
    "\n",
    "# title + body\n",
    "train_alltext_cv = alltext_cv.fit_transform(X_train['title'] + ' ' + X_train['body-text'])\n",
    "test_alltext_cv = alltext_cv.transform(X_test['title'] + ' ' + X_test['body-text'])\n",
    "\n",
    "(train_title_cv.shape, train_body_cv.shape, \n",
    "test_title_cv.shape, test_body_cv.shape,\n",
    "train_alltext_cv.shape, test_alltext_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4f18623-b41f-4f80-ae70-412ddd6937db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10th', '11', '11th', ..., 'zodiac', 'zodiacal', 'zodiacs'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8ffc7bb6-528e-4859-acb1-277e3d374639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['writers', 'writing', 'written', 'wrong', 'wrote', 'wrought',\n",
       "       'www', 'xo', 'xyz', 'yall', 'yang', 'yeah', 'year', 'yearly',\n",
       "       'years', 'yes', 'yesterday', 'yet', 'yikes', 'yods', 'yoga',\n",
       "       'york', 'you', 'young', 'younger', 'your', 'yours', 'yourself',\n",
       "       'youtube', 'yr', 'yt', 'zealot', 'zeitgeist', 'zero', 'zeus',\n",
       "       'zodiac', 'zodiacal', 'zodiacs', 'zone', 'zoom'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltext_cv.get_feature_names_out()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f81ff7-f431-4ce8-9fb4-f9f1e0b221bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0239a9a2-1ab5-402e-bcae-3ae8cfb40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rfc = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
    "gs_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [4, 5],\n",
    "    'min_impurity_decrease': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "# use gridsearch this time only to check best model params (takes a long time)\n",
    "gs = GridSearchCV(title_rfc, gs_params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7b9ecc2a-0156-4318-a05c-d72fd957ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Model Train Score (best): 0.7285986049461002\n",
      "Model Test Score (best): 0.6227848101265823\n",
      "Model Best Estimator: RandomForestClassifier(min_impurity_decrease=0.0001, min_samples_leaf=5,\n",
      "                       min_samples_split=4, n_estimators=300, n_jobs=-1,\n",
      "                       random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on titles only\n",
    "gs.fit(train_title_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(gs, \n",
    "                            (train_title_cv, y_train), \n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8fc8313-7ea8-4491-9818-596d9d2a9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params to use for later models\n",
    "rfc_params = {\n",
    "    'min_impurity_decrease': 0.0001,\n",
    "    'min_samples_leaf': 5,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 300,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae09f535-e229-4ee3-8eb6-9e1117ca40c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  66],\n",
       "       [ 83, 113]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, gs.predict(test_title_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b123faac-bb0d-4e5a-8320-02e0cf449423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.7381103360811667\n",
      "Model Test Score (best): 0.6354430379746835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on body text only - use same best params from gridsearch\n",
    "body_rfc = RandomForestClassifier(**rfc_params)\n",
    "body_rfc.fit(train_body_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(body_rfc, \n",
    "                            (train_body_cv, y_train), \n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3cd63ce8-a88c-4183-a000-6f53caa57c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.8199112238427394\n",
      "Model Test Score (best): 0.6556962025316456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on all text\n",
    "alltext_rfc = RandomForestClassifier(**rfc_params)\n",
    "alltext_rfc.fit(train_alltext_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(alltext_rfc, \n",
    "                            (train_alltext_cv, y_train), \n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40edadf-bd04-47eb-966b-d9309c265025",
   "metadata": {},
   "source": [
    "#### Analysis of Random Forest Classifier Score\n",
    "\n",
    "Perhaps unsurprisingly, analyzing on the full text (body plus title) gave better prediction accuracy. However, for purposes of the problem statement, the title and body are possibly best kept separate, as reddit does not diplay the full body text by default, and searches only display titles.\n",
    "\n",
    "Accuracy is better than baseline, but not by much. Gridsearch does not reveal too much about the possible model parameters - it just tells me that the more specific model scores better.\n",
    "\n",
    "The model is overfit (which is probably to be expected from a decision-tree-based model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181b142-f8ad-469d-9c25-9e1b4553a9b3",
   "metadata": {},
   "source": [
    "### 3a. ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "425ad43f-4764-4b0f-9b4a-9119a9bd68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Model Train Score (best): 0.7805960684844642\n",
      "Model Test Score (best): 0.6354430379746835\n",
      "Model Best Estimator: ExtraTreesClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                     min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                     random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_etc = ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
    "# use same gs_params from random forest\n",
    "title_etc_gs = GridSearchCV(title_etc, gs_params, verbose=1, n_jobs=-1)\n",
    "title_etc_gs.fit(train_title_cv, y_train)\n",
    "print(ipyutils.score_report(title_etc_gs,\n",
    "                            (train_title_cv, y_train),\n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7dede69f-bccc-48dd-9e35-2005909d76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_params = {\n",
    "    'min_impurity_decrease': 0.0001,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 200,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "99b33d6a-50dd-4417-a58f-d019032a12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.7913760304375397\n",
      "Model Test Score (best): 0.660759493670886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_etc = ExtraTreesClassifier(**etc_params)\n",
    "body_etc.fit(train_body_cv, y_train)\n",
    "print(ipyutils.score_report(body_etc,\n",
    "                            (train_body_cv, y_train),\n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f93d52f9-84d7-4018-adeb-e1e05c4fbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.8883956880152187\n",
      "Model Test Score (best): 0.6556962025316456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alltext_etc = ExtraTreesClassifier(**etc_params)\n",
    "alltext_etc.fit(train_alltext_cv, y_train)\n",
    "print(ipyutils.score_report(alltext_etc,\n",
    "                            (train_alltext_cv, y_train),\n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1a46-a11f-443c-a1df-9ce896ce34ad",
   "metadata": {},
   "source": [
    "#### Analysis of Extra Trees Classifier Score\n",
    "\n",
    "ExtraTrees did not fare any better than Random Forest on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42df3-ce1d-4a10-ba00-c8c6879bcc0b",
   "metadata": {},
   "source": [
    "### 4. Other Classifiers (Quick Comparisons)\n",
    "\n",
    "I am testing a number of other classifiers on the alltext set to see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bcd52c68-5cc8-4177-bdcd-bda851966f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9949270767279645, 0.6632911392405063)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost\n",
    "rfc = RandomForestClassifier(**rfc_params)\n",
    "ada = AdaBoostClassifier(rfc, random_state=1)\n",
    "ada.fit(train_alltext_cv, y_train)\n",
    "ada.score(train_alltext_cv, y_train), ada.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d0ae404-9996-4796-8c15-3ea2b9eae457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7076727964489538, 0.5645569620253165)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbors\n",
    "knc = KNeighborsClassifier(5)\n",
    "knc.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5c1be38a-e5ea-425c-b15d-ca9fb6ab357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7076727964489538, 0.5645569620253165)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2deab815-a991-4d89-b283-a5a441273165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7856689917564997, 0.6886075949367089)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_alltext_cv, y_train)\n",
    "mnb.score(train_alltext_cv, y_train), mnb.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b24f9-6edb-4c2d-9e81-da91c969002a",
   "metadata": {},
   "source": [
    "### 4a. Other Features with Various Classifiers\n",
    "\n",
    "There are a few other features I'd like to explore (word/character counts, for example).\n",
    "\n",
    "Date/time features might not be appropriate here due to how Reddit works and the scraping process. Reddit no longer allows search by date, so I cannot get consecutive posts over time, and I am therefore trying to get as many posts I can via searches for words. Therefore, the post distribution over time that I get from my scrapes may not be the same as the actual post distribution over time, and there is no way to verify this with my current scraping process. I have therefore decided to ignore time factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ebaa4027-9d3e-480f-9a87-15f22ffd402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'title', 'body-text', 'title-cc', 'title-wc', 'body-cc',\n",
       "       'body-wc', 'media', 'comments', 'comments_gt_median', 'day', 'month',\n",
       "       'weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b536dcd9-e057-46b3-b2f6-5f43e5983b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6011414077362079, 0.610126582278481)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "cols = ['media', 'title-cc', 'body-cc']\n",
    "pipe.fit(X_train[cols], y_train)\n",
    "pipe.score(X_train[cols], y_train), pipe.score(X_test[cols], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1a79bde8-10b3-4a0e-8b23-e70341220c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6328471781864299, 0.610126582278481)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train[cols], y_train)\n",
    "ada.score(X_train[cols], y_train), pipe.score(X_test[cols], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991dcc41-103b-460b-9cc2-48e71dfccb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
