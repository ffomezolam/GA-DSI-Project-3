{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e635b4-7f51-4771-b503-3991eb4065e4",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Part 2: Modeling\n",
    "\n",
    "Model data for fun and profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99841833-554e-40b2-b472-4a57b0cf38be",
   "metadata": {},
   "source": [
    "### 0. Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50529b0d-9aea-49b6-9429-7f6b910de60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# pipelines, gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# nltk - for stopwords and stemming\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# custom\n",
    "import ipynb_utils as ipyutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96d9fe-61c8-4b4e-8909-50c00610ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_json('../data/scrapes-clean.json', orient='index')\n",
    "\n",
    "# convert time to datetime object\n",
    "df['time'] = pd.to_datetime(df['time'], format=ipyutils.DATE_FMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6020c18d-2747-4806-bdfd-94cdda105993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>Saturn Return MEGATHREAD - we've been getting ...</td>\n",
       "      <td></td>\n",
       "      <td>214</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>MERCURY RX INFOGRAPHIC: Taurus/Gemini, Apr-Jun...</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>CHANI app issues?</td>\n",
       "      <td>I just downloaded the CHANI app to try out and...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>221</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>Is Mercury in Aquarius in the 6th House as pow...</td>\n",
       "      <td>Not new to the deeper parts of astrology but t...</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>314</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>What is the proper orb for a sextile?</td>\n",
       "      <td>What is the proper and respective orb for a se...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title  \\\n",
       "0 2022-02-01  Saturn Return MEGATHREAD - we've been getting ...   \n",
       "1 2022-06-01  MERCURY RX INFOGRAPHIC: Taurus/Gemini, Apr-Jun...   \n",
       "2 2022-08-30                                  CHANI app issues?   \n",
       "4 2022-08-30  Is Mercury in Aquarius in the 6th House as pow...   \n",
       "5 2022-08-30              What is the proper orb for a sextile?   \n",
       "\n",
       "                                           body-text  title-cc  title-wc  \\\n",
       "0                                                          214        35   \n",
       "1                                                           51         8   \n",
       "2  I just downloaded the CHANI app to try out and...        17         3   \n",
       "4  Not new to the deeper parts of astrology but t...        86        17   \n",
       "5  What is the proper and respective orb for a se...        37         7   \n",
       "\n",
       "   body-cc  body-wc  media  comments  \n",
       "0        0        0      0       330  \n",
       "1        0        0      0        22  \n",
       "2      221       40      0         4  \n",
       "4      314       56      0         8  \n",
       "5      224       42      0         8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all looks good...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68d3abe-7eda-4afc-aad8-c0fb1bdc3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         datetime64[ns]\n",
       "title                object\n",
       "body-text            object\n",
       "title-cc              int64\n",
       "title-wc              int64\n",
       "body-cc               int64\n",
       "body-wc               int64\n",
       "media                 int64\n",
       "comments              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and that the right datatypes are showing\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f070fd-61b1-4867-9525-09cf7396a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ea98a-32ed-4d4f-9d19-1524ee3836ae",
   "metadata": {},
   "source": [
    "### 0.5. Problem Statement\n",
    "\n",
    "What characteristics of a post on Reddit are most predictive of the overall interaction on a thread (as measured by number of comments)?\n",
    "\n",
    "Model will attempt to predict whether or not a given Reddit post will have above or below the median number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa388c-79f9-48bd-bb58-3b48e0aa7a62",
   "metadata": {},
   "source": [
    "### 1. Generate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50e06b6-908f-48bf-9da0-45e59538381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median comments\n",
    "median = np.median(df['comments'])\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb5882c-281f-4590-87a3-9d02cd06c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    993\n",
       "1    979\n",
       "Name: comments_gt_median, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target column\n",
    "df['comments_gt_median'] = (df['comments'] > median).astype(int)\n",
    "df['comments_gt_median'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60706e98-2d48-4241-8b04-7b9945ab2a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50355\n",
       "1    0.49645\n",
       "Name: comments_gt_median, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_gt_median'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4b475-21fc-492b-8192-0e8fb9e2e5e9",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "Baseline is just about **50%**, as it should be since we are using median as split for determining high vs. low engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff91f72-3c70-4c85-a04c-404b0cf25365",
   "metadata": {},
   "source": [
    "### 1a. Split Time Column\n",
    "\n",
    "Might want to check by month or day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff00a030-b964-4f6f-86b7-2dc6be418e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['time'].apply(ipyutils.get_day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113fea0d-7c35-450b-9f5c-380b93291297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['time'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b59e1340-568b-48d4-a6e8-30601e41c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month\n",
       "0    1      2\n",
       "1    2      6\n",
       "2    1      8\n",
       "4    1      8\n",
       "5    1      8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['day','month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec924ed-83a8-4c00-9193-0a2add1b6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     1\n",
       "8     1\n",
       "10    1\n",
       "11    1\n",
       "Name: weekend, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekend'] = (df['day'] > 5).astype(int)\n",
    "df['weekend'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb886e1-140e-4947-8eb2-2affc76f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this just to be safe as I've gotten some weird row mismatches\n",
    "# later on and not sure exactly why\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421586c-0e19-4b86-8f58-b8ebdd3d751c",
   "metadata": {},
   "source": [
    "### 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff9ecee-a22a-42de-bba7-c90e944b8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1380, 11), (592, 11), (1380,), (592,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = 'comments_gt_median'\n",
    "cols_to_drop = ['time'] # don't need this any more\n",
    "X = df.drop(columns=[col_target]+cols_to_drop)\n",
    "y = df[col_target]\n",
    "\n",
    "# split to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20637c-93dd-4710-aa9f-36f5ab8d8867",
   "metadata": {},
   "source": [
    "### 3. Count Vectorize Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "705ff509-48f0-40e7-b192-8caa78ecb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for testing stemming - taken from course \n",
    "# materials 33-nlp-ii\n",
    "def stem_tokenizer(doc):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "def lemma_tokenizer(doc):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "# I tried these on the CountVectorizer and they result in some bogus matches\n",
    "# (like whitespace and punctuation). I don't have time to really look into this,\n",
    "# and the scores from my tests on these were not very different from not using\n",
    "# them, so I'm not going to use them this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8f5ffad-24f9-4d37-8311-791f9d141dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1380, 1440),\n",
       " (592, 1440),\n",
       " (1380, 6368),\n",
       " (592, 6368),\n",
       " (1380, 7440),\n",
       " (592, 7440))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count vectorize tables\n",
    "cv_params = {\n",
    "    'token_pattern': ipyutils.PAT_TOKEN,\n",
    "    'min_df': 2,\n",
    "    'stop_words': stopwords.words('english'),\n",
    "    'ngram_range': (1,2),\n",
    "    'tokenizer': None # tried stem_tokenizer, lemma_tokenizer\n",
    "}\n",
    "cv_title = CountVectorizer(**cv_params)\n",
    "cv_body = CountVectorizer(**cv_params)\n",
    "cv_alltext = CountVectorizer(**cv_params)\n",
    "\n",
    "# title\n",
    "train_title_cv = cv_title.fit_transform(X_train['title'])\n",
    "test_title_cv = cv_title.transform(X_test['title'])\n",
    "\n",
    "# body\n",
    "train_body_cv = cv_body.fit_transform(X_train['body-text'])\n",
    "test_body_cv = cv_body.transform(X_test['body-text'])\n",
    "\n",
    "# title + body\n",
    "train_alltext_cv = cv_alltext.fit_transform(X_train['title'] + ' ' + X_train['body-text'])\n",
    "test_alltext_cv = cv_alltext.transform(X_test['title'] + ' ' + X_test['body-text'])\n",
    "\n",
    "(train_title_cv.shape, test_title_cv.shape, \n",
    "train_body_cv.shape, test_body_cv.shape,\n",
    "train_alltext_cv.shape, test_alltext_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4f18623-b41f-4f80-ae70-412ddd6937db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['years', 'years ago', 'years day', 'yes', 'yesterday', 'yet',\n",
       "       'yods', 'youtube', 'yr', 'zodiac', 'zodiac beauty',\n",
       "       'zodiac collection', 'zodiac illustration', 'zodiac series',\n",
       "       'zodiac sign', 'zodiac signs', 'zodiac war', 'zodiac witch',\n",
       "       'zodiacal', 'zodiacs'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_title.get_feature_names_out()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ffc7bb6-528e-4859-acb1-277e3d374639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['year transits', 'yearly', 'years', 'years ago', 'years day',\n",
       "       'years old', 'years sign', 'years since', 'years still', 'yes',\n",
       "       'yesterday', 'yet', 'yet never', 'yikes', 'yods', 'yoga', 'york',\n",
       "       'young', 'young people', 'younger', 'youtube', 'youtube videos',\n",
       "       'yr', 'yt', 'zealot', 'zeitgeist', 'zeus', 'zodiac',\n",
       "       'zodiac beauty', 'zodiac collection', 'zodiac illustration',\n",
       "       'zodiac series', 'zodiac sign', 'zodiac signs', 'zodiac war',\n",
       "       'zodiac witch', 'zodiacal', 'zodiacs', 'zone', 'zoom'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_alltext.get_feature_names_out()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f81ff7-f431-4ce8-9fb4-f9f1e0b221bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0239a9a2-1ab5-402e-bcae-3ae8cfb40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rfc = RandomForestClassifier()\n",
    "gs_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [4, 5],\n",
    "    'min_impurity_decrease': [0.0001, 0.001],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "# use gridsearch this time only to check best model params (takes a long time)\n",
    "gs = GridSearchCV(title_rfc, gs_params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b9ecc2a-0156-4318-a05c-d72fd957ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Model Train Score (best): 0.722463768115942\n",
      "Model Test Score (best): 0.6148648648648649\n",
      "Model Best Estimator: RandomForestClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on titles only\n",
    "gs.fit(train_title_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(gs, \n",
    "                            (train_title_cv, y_train), \n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d54fc9a9-2705-40eb-9203-2332dfd49306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_impurity_decrease': 0.0001,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8fc8313-7ea8-4491-9818-596d9d2a9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params to use for later models\n",
    "rfc_params = gs.best_params_\n",
    "# {\n",
    "#     'min_impurity_decrease': 0.0001,\n",
    "#     'min_samples_leaf': 5,\n",
    "#     'min_samples_split': 4,\n",
    "#     'n_estimators': 300,\n",
    "#     'n_jobs': -1,\n",
    "#     'random_state': 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b123faac-bb0d-4e5a-8320-02e0cf449423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.7615942028985507\n",
      "Model Test Score (best): 0.6537162162162162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on body text only - use same best params from gridsearch\n",
    "body_rfc = RandomForestClassifier(**rfc_params)\n",
    "body_rfc.fit(train_body_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(body_rfc, \n",
    "                            (train_body_cv, y_train), \n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3cd63ce8-a88c-4183-a000-6f53caa57c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.8289855072463768\n",
      "Model Test Score (best): 0.6638513513513513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on all text\n",
    "alltext_rfc = RandomForestClassifier(**rfc_params)\n",
    "alltext_rfc.fit(train_alltext_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(alltext_rfc, \n",
    "                            (train_alltext_cv, y_train), \n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6edc7-132a-4475-bb2d-a00a84a517d2",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2179dc31-60cf-4e36-bbce-360d51481ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.60      0.71      0.65       298\n",
      "         low       0.64      0.52      0.57       294\n",
      "\n",
      "    accuracy                           0.61       592\n",
      "   macro avg       0.62      0.61      0.61       592\n",
      "weighted avg       0.62      0.61      0.61       592\n",
      "\n",
      "True Positives: 153\n",
      "True Negatives: 211\n",
      "False Positives: 87\n",
      "False Negatives: 141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# title words\n",
    "print(ipyutils.metrics_report(gs.best_estimator_, y_test, test_title_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed8e8a93-fe21-46be-89e5-0b812b2ff8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.71      0.53      0.61       298\n",
      "         low       0.62      0.78      0.69       294\n",
      "\n",
      "    accuracy                           0.65       592\n",
      "   macro avg       0.66      0.65      0.65       592\n",
      "weighted avg       0.66      0.65      0.65       592\n",
      "\n",
      "True Positives: 229\n",
      "True Negatives: 158\n",
      "False Positives: 140\n",
      "False Negatives: 65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# body words\n",
    "print(ipyutils.metrics_report(body_rfc, y_test, test_body_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14307311-65b9-4473-b0d4-d5fd5b03a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.64      0.74      0.69       298\n",
      "         low       0.69      0.58      0.63       294\n",
      "\n",
      "    accuracy                           0.66       592\n",
      "   macro avg       0.67      0.66      0.66       592\n",
      "weighted avg       0.67      0.66      0.66       592\n",
      "\n",
      "True Positives: 171\n",
      "True Negatives: 222\n",
      "False Positives: 76\n",
      "False Negatives: 123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all words\n",
    "print(ipyutils.metrics_report(alltext_rfc, y_test, test_alltext_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40edadf-bd04-47eb-966b-d9309c265025",
   "metadata": {},
   "source": [
    "#### Analysis of Random Forest Classifier Score\n",
    "\n",
    "Perhaps unsurprisingly, analyzing on the full text (body plus title) gave better prediction accuracy. However, for purposes of the problem statement, the title and body are possibly best kept separate, as reddit does not diplay the full body text by default, and searches only display titles.\n",
    "\n",
    "Accuracy is better than baseline, but not by a huge amount. Gridsearch does not reveal too much about the possible model parameters - it just tells me that the more specific model scores better.\n",
    "\n",
    "The model is overfit (which is probably to be expected from a decision-tree-based model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99bf60-d9a8-44e4-8cb7-d15db687edda",
   "metadata": {},
   "source": [
    "#### Exploration of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a4c66b7-d1bd-4a8b-943e-b373daa88f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title exploration - what words were best predictors?\n",
    "# get predictions\n",
    "preds_test = gs.best_estimator_.predict(test_title_cv)\n",
    "Xdf = pd.DataFrame(test_title_cv.A, \n",
    "                   columns=cv_title.get_feature_names_out(),\n",
    "                   index=y_test.index)\n",
    "# get filter for correct predictions (use index to label)\n",
    "preds_correct_filt = (preds_test == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e7a766d-d6ec-4bb5-9320-f1e92ae4e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>moon</th>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquarius</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planet</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chart</th>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorpio</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planets</th>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astrology</th>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pluto</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           correct  incorrect  diff\n",
       "moon            40         22    18\n",
       "aquarius        16          2    14\n",
       "planet          18          4    14\n",
       "chart           40         26    14\n",
       "scorpio         15          3    12\n",
       "planets         22         10    12\n",
       "anyone          14          3    11\n",
       "book            14          4    10\n",
       "astrology       47         38     9\n",
       "pluto           17          8     9"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word counts for correct and incorrect predictions\n",
    "wordcounts = pd.DataFrame()\n",
    "wordcounts['correct'] = Xdf.loc[preds_correct_filt].sum()\n",
    "wordcounts['incorrect'] = Xdf[~preds_correct_filt].sum()\n",
    "\n",
    "# get difference of correct and incorrect predictions per word\n",
    "# This shows what words had more correct over incorrect predictions\n",
    "wordcounts['diff'] = wordcounts['correct'] - wordcounts['incorrect']\n",
    "\n",
    "wordcounts.sort_values(by='diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181b142-f8ad-469d-9c25-9e1b4553a9b3",
   "metadata": {},
   "source": [
    "### 3a. ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "425ad43f-4764-4b0f-9b4a-9119a9bd68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Model Train Score (best): 0.7702898550724637\n",
      "Model Test Score (best): 0.6233108108108109\n",
      "Model Best Estimator: ExtraTreesClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                     min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                     random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_etc = ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
    "# use same gs_params from random forest\n",
    "title_etc_gs = GridSearchCV(title_etc, gs_params, verbose=1, n_jobs=-1)\n",
    "title_etc_gs.fit(train_title_cv, y_train)\n",
    "print(ipyutils.score_report(title_etc_gs,\n",
    "                            (train_title_cv, y_train),\n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7dede69f-bccc-48dd-9e35-2005909d76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_params = {\n",
    "    'min_impurity_decrease': 0.0001,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 200,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99b33d6a-50dd-4417-a58f-d019032a12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.7934782608695652\n",
      "Model Test Score (best): 0.6672297297297297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_etc = ExtraTreesClassifier(**etc_params)\n",
    "body_etc.fit(train_body_cv, y_train)\n",
    "print(ipyutils.score_report(body_etc,\n",
    "                            (train_body_cv, y_train),\n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f93d52f9-84d7-4018-adeb-e1e05c4fbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.8695652173913043\n",
      "Model Test Score (best): 0.6722972972972973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alltext_etc = ExtraTreesClassifier(**etc_params)\n",
    "alltext_etc.fit(train_alltext_cv, y_train)\n",
    "print(ipyutils.score_report(alltext_etc,\n",
    "                            (train_alltext_cv, y_train),\n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1a46-a11f-443c-a1df-9ce896ce34ad",
   "metadata": {},
   "source": [
    "#### Analysis of Extra Trees Classifier Score\n",
    "\n",
    "ExtraTrees did not fare any better than Random Forest on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42df3-ce1d-4a10-ba00-c8c6879bcc0b",
   "metadata": {},
   "source": [
    "### 4. Other Classifiers (Quick Comparisons)\n",
    "\n",
    "I am testing a number of other classifiers on the alltext set to see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcd52c68-5cc8-4177-bdcd-bda851966f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9884057971014493, 0.6638513513513513)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost\n",
    "rfc = RandomForestClassifier(**rfc_params)\n",
    "ada = AdaBoostClassifier(rfc, random_state=1)\n",
    "ada.fit(train_alltext_cv, y_train)\n",
    "ada.score(train_alltext_cv, y_train), ada.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d0ae404-9996-4796-8c15-3ea2b9eae457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6659420289855073, 0.5168918918918919)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbors\n",
    "knc = KNeighborsClassifier(5)\n",
    "knc.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c1be38a-e5ea-425c-b15d-ca9fb6ab357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6659420289855073, 0.5168918918918919)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2deab815-a991-4d89-b283-a5a441273165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8485507246376811, 0.6706081081081081)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_alltext_cv, y_train)\n",
    "mnb.score(train_alltext_cv, y_train), mnb.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a3678-2005-4494-9218-147afcbdb87e",
   "metadata": {},
   "source": [
    "#### Analysis of Other Classifiers on Word Vectors\n",
    "\n",
    "Naive Bayes performed best, with AdaBoost second. AdaBoost was severely overfit. Naive Bayes was a bit more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b24f9-6edb-4c2d-9e81-da91c969002a",
   "metadata": {},
   "source": [
    "### 4a. Other Features with Various Classifiers\n",
    "\n",
    "There are a few other features I'd like to explore (word/character counts, for example).\n",
    "\n",
    "Date/time features might not be appropriate here due to how Reddit works and the scraping process. Reddit no longer allows search by date, so I cannot get consecutive posts over time, and I am therefore trying to get as many posts I can via searches for words. Therefore, the post distribution over time that I get from my scrapes may not be the same as the actual post distribution over time, and there is no way to verify this with my current scraping process. If I have enough posts from different dates I could possibly consider distribution requirement satisfied, but I'm a bit skeptical now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebaa4027-9d3e-480f-9a87-15f22ffd402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'title', 'body-text', 'title-cc', 'title-wc', 'body-cc',\n",
       "       'body-wc', 'media', 'comments', 'comments_gt_median', 'day', 'month',\n",
       "       'weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a718e-2a72-4892-acfc-5d7e505ba219",
   "metadata": {},
   "source": [
    "#### Word- and Character-counts and Media Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7209ab69-89ce-422d-8659-6a537d08ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to test all of the following feature combinations just to see if\n",
    "# they show any major differences\n",
    "col_opts = [\n",
    "    ['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc'],\n",
    "    ['media'],\n",
    "    ['title-cc', 'title-wc'],\n",
    "    ['body-cc', 'body-wc'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc'],\n",
    "    ['day'],\n",
    "    ['month'],\n",
    "    ['day', 'month'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b536dcd9-e057-46b3-b2f6-5f43e5983b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain: 0.8028985507246377\n",
      "\ttest: 0.6351351351351351\n",
      "['media']\n",
      "\ttrain: 0.5434782608695652\n",
      "\ttest: 0.543918918918919\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain: 0.6659420289855073\n",
      "\ttest: 0.5337837837837838\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain: 0.6855072463768116\n",
      "\ttest: 0.5929054054054054\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain: 0.8079710144927537\n",
      "\ttest: 0.6131756756756757\n",
      "['day']\n",
      "\ttrain: 0.6181159420289855\n",
      "\ttest: 0.597972972972973\n",
      "['month']\n",
      "\ttrain: 0.6876811594202898\n",
      "\ttest: 0.7010135135135135\n",
      "['day', 'month']\n",
      "\ttrain: 0.6876811594202898\n",
      "\ttest: 0.7010135135135135\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain: 0.8028985507246377\n",
      "\ttest: 0.6452702702702703\n"
     ]
    }
   ],
   "source": [
    "# loop over each feature combination and run a model\n",
    "for opt in col_opts:\n",
    "    xrfc = RandomForestClassifier(**rfc_params)\n",
    "    xrfc.fit(X_train[opt], y_train)\n",
    "    print(f'{opt}\\n\\ttrain: {xrfc.score(X_train[opt], y_train)}'\\\n",
    "          + f'\\n\\ttest: {xrfc.score(X_test[opt], y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "991dcc41-103b-460b-9cc2-48e71dfccb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 1445) (592, 1445)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1444) (592, 1444)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1445) (592, 1445)\n"
     ]
    }
   ],
   "source": [
    "# now let's do the same but adding the Vectorized title\n",
    "\n",
    "# make vectorized title dataframes\n",
    "train_title_cv_df = ipyutils.df_from_cv(cv_title, train_title_cv, X_train.index)\n",
    "test_title_cv_df = ipyutils.df_from_cv(cv_title, test_title_cv, X_test.index)\n",
    "\n",
    "# concat all column combos to vectorized title dataframes\n",
    "combo_dfs = list()\n",
    "for opt in col_opts:\n",
    "    # 0 is train, 1 is test\n",
    "    combo_dfs.append((ipyutils.easy_concat(X_train[opt], train_title_cv_df),\n",
    "                      ipyutils.easy_concat(X_test[opt], test_title_cv_df)))\n",
    "\n",
    "# check for integrity\n",
    "for cdf in combo_dfs:\n",
    "    print(cdf[0].shape, cdf[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "941acabc-f0f9-4fc1-9da7-bed61b138cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain:0.7028985507246377\n",
      "\ttest:0.643581081081081\n",
      "['media']\n",
      "\ttrain:0.6992753623188406\n",
      "\ttest:0.6131756756756757\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain:0.6905797101449276\n",
      "\ttest:0.6452702702702703\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain:0.7057971014492753\n",
      "\ttest:0.6351351351351351\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain:0.7043478260869566\n",
      "\ttest:0.6469594594594594\n",
      "['day']\n",
      "\ttrain:0.7057971014492753\n",
      "\ttest:0.6402027027027027\n",
      "['month']\n",
      "\ttrain:0.7231884057971014\n",
      "\ttest:0.6976351351351351\n",
      "['day', 'month']\n",
      "\ttrain:0.7188405797101449\n",
      "\ttest:0.6942567567567568\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain:0.7028985507246377\n",
      "\ttest:0.6672297297297297\n"
     ]
    }
   ],
   "source": [
    "# run a model on each combo\n",
    "for ix, cdf in enumerate(combo_dfs):\n",
    "    opt = col_opts[ix]\n",
    "    xrfc.fit(cdf[0], y_train)\n",
    "    print(f'{opt}\\n\\ttrain:{xrfc.score(cdf[0], y_train)}\\n'\\\n",
    "          + f'\\ttest:{xrfc.score(cdf[1], y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872cb055-8a93-4e1d-8e3e-85dfc1622ac9",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "From what I've seen so far, adding vectorized text data seems to even out the model a bit, with less overfitting than when using just word- and character-count features.\n",
    "\n",
    "**However...** no model seems to be able to reach 70%+ accuracy. We are stuck in the 60% zone.\n",
    "\n",
    "I'm doing all of this right now on a very small subset of data so all subject to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba82f31-612b-4161-ad87-a6430da8a3bc",
   "metadata": {},
   "source": [
    "#### Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f921e5d3-09c2-4a2d-8c1d-f44b4d9c165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484.0</td>\n",
       "      <td>43.442149</td>\n",
       "      <td>40.767618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>29.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>47.452381</td>\n",
       "      <td>75.077262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.75</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>28.829268</td>\n",
       "      <td>38.206191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.25</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>564.0</td>\n",
       "      <td>80.189716</td>\n",
       "      <td>175.136134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307.0</td>\n",
       "      <td>35.684039</td>\n",
       "      <td>48.040096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.0</td>\n",
       "      <td>27.331658</td>\n",
       "      <td>37.591512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>212.0</td>\n",
       "      <td>52.485849</td>\n",
       "      <td>70.056475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count       mean         std  min    25%   50%    75%     max\n",
       "day                                                               \n",
       "0    484.0  43.442149   40.767618  0.0  14.75  29.0  61.00   255.0\n",
       "1     42.0  47.452381   75.077262  0.0   7.25  20.0  53.75   359.0\n",
       "2    164.0  28.829268   38.206191  0.0   6.00  14.0  31.25   224.0\n",
       "3    564.0  80.189716  175.136134  0.0  19.00  42.0  89.00  3100.0\n",
       "4    307.0  35.684039   48.040096  0.0  10.00  21.0  43.00   368.0\n",
       "5    199.0  27.331658   37.591512  0.0   4.50  13.0  34.00   207.0\n",
       "6    212.0  52.485849   70.056475  0.0   8.00  30.0  72.25   596.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('day')['comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bde61-66ab-4a60-abbd-2e3d7be01c9f",
   "metadata": {},
   "source": [
    "**NOTES** Thursday seems to be a hot day for comments, with a much higher mean, median, and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7324461-171a-4987-9641-180857654837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>97.888889</td>\n",
       "      <td>49.936070</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>139.00</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>159.250000</td>\n",
       "      <td>86.289794</td>\n",
       "      <td>47.0</td>\n",
       "      <td>118.75</td>\n",
       "      <td>141.0</td>\n",
       "      <td>182.00</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.0</td>\n",
       "      <td>23.722222</td>\n",
       "      <td>32.812362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>24.25</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159.0</td>\n",
       "      <td>24.981132</td>\n",
       "      <td>33.494468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.50</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>174.0</td>\n",
       "      <td>29.885057</td>\n",
       "      <td>33.677466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>15.5</td>\n",
       "      <td>37.00</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124.0</td>\n",
       "      <td>26.008065</td>\n",
       "      <td>29.621322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>254.0</td>\n",
       "      <td>34.818898</td>\n",
       "      <td>56.249292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.50</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>188.0</td>\n",
       "      <td>26.675532</td>\n",
       "      <td>42.299619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.25</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>927.0</td>\n",
       "      <td>73.365696</td>\n",
       "      <td>140.831429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>51.545455</td>\n",
       "      <td>36.835753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>54.0</td>\n",
       "      <td>84.50</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>84.013888</td>\n",
       "      <td>43.0</td>\n",
       "      <td>70.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>153.00</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>56.484300</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.50</td>\n",
       "      <td>87.0</td>\n",
       "      <td>115.50</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count        mean         std   min     25%    50%     75%     max\n",
       "month                                                                    \n",
       "1        9.0   97.888889   49.936070  26.0   64.00   80.0  139.00   166.0\n",
       "2        8.0  159.250000   86.289794  47.0  118.75  141.0  182.00   330.0\n",
       "3      108.0   23.722222   32.812362   0.0    6.00   11.5   24.25   198.0\n",
       "4      159.0   24.981132   33.494468   0.0    4.00   12.0   31.50   196.0\n",
       "5      174.0   29.885057   33.677466   0.0    7.25   15.5   37.00   159.0\n",
       "6      124.0   26.008065   29.621322   1.0    7.00   15.0   30.25   152.0\n",
       "7      254.0   34.818898   56.249292   0.0    6.00   14.0   37.50   390.0\n",
       "8      188.0   26.675532   42.299619   0.0    5.00   11.0   29.25   359.0\n",
       "9      927.0   73.365696  140.831429   2.0   23.00   44.0   85.00  3100.0\n",
       "10      11.0   51.545455   36.835753   0.0   14.50   54.0   84.50    99.0\n",
       "11       3.0  116.333333   84.013888  43.0   70.50   98.0  153.00   208.0\n",
       "12       7.0   85.142857   56.484300  22.0   40.50   87.0  115.50   175.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('month')['comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d015-1bdf-4ce4-81df-095311174c03",
   "metadata": {},
   "source": [
    "**NOTES** not enough month data right now, with very low counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddcbe7-769d-4bfa-a242-9ad0fcaa4bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
