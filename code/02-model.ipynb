{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e635b4-7f51-4771-b503-3991eb4065e4",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Part 2: Modeling\n",
    "\n",
    "Model data for fun and profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99841833-554e-40b2-b472-4a57b0cf38be",
   "metadata": {},
   "source": [
    "### 0. Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50529b0d-9aea-49b6-9429-7f6b910de60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# pipelines, gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# nltk - for stopwords and stemming\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# custom\n",
    "import ipynb_utils as ipyutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96d9fe-61c8-4b4e-8909-50c00610ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_json('../data/scrapes-clean.json', orient='index')\n",
    "\n",
    "# convert time to datetime object\n",
    "df['time'] = pd.to_datetime(df['time'], format=ipyutils.DATE_FMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6020c18d-2747-4806-bdfd-94cdda105993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Newbie questions about ascendants and borders</td>\n",
       "      <td>I'm new to actually learning astrology, not ju...</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Astrology and cognitive dissonance</td>\n",
       "      <td>Open to anyone who wouldn't mind sharing a rec...</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>what do y’all think of persona charts?</td>\n",
       "      <td>I feel a bit skeptical of them, since I feel l...</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>180</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>RESOURCE REQUEST: Videos (or articles) with ti...</td>\n",
       "      <td>I think my problem is that I don’t know the pr...</td>\n",
       "      <td>160</td>\n",
       "      <td>24</td>\n",
       "      <td>597</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>people who have had saturn transit their 10th,...</td>\n",
       "      <td>How did it affect your career? Did it impact y...</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>116</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title  \\\n",
       "0 2022-09-05      Newbie questions about ascendants and borders   \n",
       "2 2022-09-05                 Astrology and cognitive dissonance   \n",
       "3 2022-09-05             what do y’all think of persona charts?   \n",
       "4 2022-09-05  RESOURCE REQUEST: Videos (or articles) with ti...   \n",
       "5 2022-09-05  people who have had saturn transit their 10th,...   \n",
       "\n",
       "                                           body-text  title-cc  title-wc  \\\n",
       "0  I'm new to actually learning astrology, not ju...        45         6   \n",
       "2  Open to anyone who wouldn't mind sharing a rec...        34         4   \n",
       "3  I feel a bit skeptical of them, since I feel l...        38         7   \n",
       "4  I think my problem is that I don’t know the pr...       160        24   \n",
       "5  How did it affect your career? Did it impact y...        64        12   \n",
       "\n",
       "   body-cc  body-wc  media  comments  \n",
       "0      601      107      0         0  \n",
       "2      323       49      0         1  \n",
       "3      180       29      0         0  \n",
       "4      597       94      0         2  \n",
       "5      116       22      0        11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all looks good...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68d3abe-7eda-4afc-aad8-c0fb1bdc3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         datetime64[ns]\n",
       "title                object\n",
       "body-text            object\n",
       "title-cc              int64\n",
       "title-wc              int64\n",
       "body-cc               int64\n",
       "body-wc               int64\n",
       "media                 int64\n",
       "comments              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and that the right datatypes are showing\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f070fd-61b1-4867-9525-09cf7396a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8413, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ea98a-32ed-4d4f-9d19-1524ee3836ae",
   "metadata": {},
   "source": [
    "### 0.5. Problem Statement\n",
    "\n",
    "What characteristics of a post on Reddit are most predictive of the overall interaction on a thread (as measured by number of comments)?\n",
    "\n",
    "Model will attempt to predict whether or not a given Reddit post will have above or below the median number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa388c-79f9-48bd-bb58-3b48e0aa7a62",
   "metadata": {},
   "source": [
    "### 1. Generate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50e06b6-908f-48bf-9da0-45e59538381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median comments\n",
    "median = np.median(df['comments'])\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb5882c-281f-4590-87a3-9d02cd06c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4271\n",
       "1    4142\n",
       "Name: comments_gt_median, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target column\n",
    "df['comments_gt_median'] = (df['comments'] > median).astype(int)\n",
    "df['comments_gt_median'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60706e98-2d48-4241-8b04-7b9945ab2a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.507667\n",
       "1    0.492333\n",
       "Name: comments_gt_median, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_gt_median'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4b475-21fc-492b-8192-0e8fb9e2e5e9",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "Baseline is just about **50%**, as it should be since we are using median as split for determining high vs. low engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ad8adc-1972-46c6-94c7-bc5445d0003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in obvious variable\n",
    "TARGET = df['comments_gt_median']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff91f72-3c70-4c85-a04c-404b0cf25365",
   "metadata": {},
   "source": [
    "### 1a. Split Time Column\n",
    "\n",
    "Might want to check by month or day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff00a030-b964-4f6f-86b7-2dc6be418e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['time'].apply(ipyutils.get_day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113fea0d-7c35-450b-9f5c-380b93291297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['time'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59e1340-568b-48d4-a6e8-30601e41c78b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month\n",
       "0    0      9\n",
       "2    0      9\n",
       "3    0      9\n",
       "4    0      9\n",
       "5    0      9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['day','month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec924ed-83a8-4c00-9193-0a2add1b6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "10    0\n",
       "11    0\n",
       "Name: weekend, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekend'] = (df['day'] > 5).astype(int)\n",
    "df['weekend'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cb886e1-140e-4947-8eb2-2affc76f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this just to be safe as I've gotten some weird row mismatches\n",
    "# later on and not sure exactly why\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421586c-0e19-4b86-8f58-b8ebdd3d751c",
   "metadata": {},
   "source": [
    "### 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff9ecee-a22a-42de-bba7-c90e944b8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6730, 11), (1683, 11), (6730,), (1683,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = 'comments_gt_median'\n",
    "cols_to_drop = ['time'] # don't need this any more\n",
    "X = df.drop(columns=[col_target]+cols_to_drop)\n",
    "y = df[col_target]\n",
    "\n",
    "# split to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20637c-93dd-4710-aa9f-36f5ab8d8867",
   "metadata": {},
   "source": [
    "### 3. Count Vectorize Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705ff509-48f0-40e7-b192-8caa78ecb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for testing stemming - taken from course \n",
    "# materials 33-nlp-ii\n",
    "def stem_tokenizer(doc):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "def lemma_tokenizer(doc):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "# I tried these on the CountVectorizer and they result in some bogus matches\n",
    "# (like whitespace and punctuation). I don't have time to really look into this,\n",
    "# and the scores from my tests on these were not very different from not using\n",
    "# them, so I'm not going to use them this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8f5ffad-24f9-4d37-8311-791f9d141dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6730, 588),\n",
       " (1683, 588),\n",
       " (6730, 3994),\n",
       " (1683, 3994),\n",
       " (6730, 4355),\n",
       " (1683, 4355))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count vectorize tables\n",
    "cv_params = {\n",
    "    'token_pattern': ipyutils.PAT_TOKEN, # using standard CV token pattern\n",
    "    'min_df': 15, # we don't want words that rarely appear\n",
    "    'stop_words': stopwords.words('english'), # use nltk stopwords list\n",
    "    'ngram_range': (1,3), # allow short phrases\n",
    "    'tokenizer': None # tried stem_tokenizer, lemma_tokenizer - using neither\n",
    "}\n",
    "cv_title = CountVectorizer(**cv_params)\n",
    "cv_body = CountVectorizer(**cv_params)\n",
    "cv_alltext = CountVectorizer(**cv_params)\n",
    "\n",
    "# title\n",
    "train_title_cv = cv_title.fit_transform(X_train['title'])\n",
    "test_title_cv = cv_title.transform(X_test['title'])\n",
    "\n",
    "# body\n",
    "train_body_cv = cv_body.fit_transform(X_train['body-text'])\n",
    "test_body_cv = cv_body.transform(X_test['body-text'])\n",
    "\n",
    "# title + body\n",
    "train_alltext_cv = cv_alltext.fit_transform(X_train['title'] + ' ' + X_train['body-text'])\n",
    "test_alltext_cv = cv_alltext.transform(X_test['title'] + ' ' + X_test['body-text'])\n",
    "\n",
    "(train_title_cv.shape, test_title_cv.shape, \n",
    "train_body_cv.shape, test_body_cv.shape,\n",
    "train_alltext_cv.shape, test_alltext_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b4f18623-b41f-4f80-ae70-412ddd6937db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['week', 'well', 'western', 'whole', 'whole sign', 'within',\n",
       "       'without', 'wondering', 'work', 'working', 'world', 'would',\n",
       "       'wrong', 'year', 'years', 'yet', 'youtube', 'zodiac',\n",
       "       'zodiac sign', 'zodiac signs'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_title.get_feature_names_out()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ffc7bb6-528e-4859-acb1-277e3d374639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wrong', 'wrote', 'www', 'www astro', 'www astro com',\n",
       "       'www reddit', 'www reddit com', 'www youtube', 'www youtube com',\n",
       "       'ya', 'yang', 'yeah', 'year', 'year ago', 'year half', 'years',\n",
       "       'years ago', 'years old', 'yes', 'yesterday', 'yet', 'yin',\n",
       "       'young', 'younger', 'youtu', 'youtube', 'youtube channel',\n",
       "       'youtube com', 'youtube com watch', 'youtube video',\n",
       "       'youtube videos', 'youtubers', 'zero', 'zeus', 'zodiac',\n",
       "       'zodiac sign', 'zodiac signs', 'zodiacal', 'zodiacs', 'zone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_alltext.get_feature_names_out()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f81ff7-f431-4ce8-9fb4-f9f1e0b221bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0239a9a2-1ab5-402e-bcae-3ae8cfb40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rfc = RandomForestClassifier()\n",
    "gs_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [4, 5],\n",
    "    'min_impurity_decrease': [0.0001, 0.001],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "# use gridsearch this time only to check best model params (takes a long time)\n",
    "gs = GridSearchCV(title_rfc, gs_params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b9ecc2a-0156-4318-a05c-d72fd957ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Model Train Score (best): 0.7286775631500743\n",
      "Model Test Score (best): 0.6428995840760546\n",
      "Model Best Estimator: RandomForestClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on titles only\n",
    "gs.fit(train_title_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(gs, \n",
    "                            (train_title_cv, y_train), \n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8fc8313-7ea8-4491-9818-596d9d2a9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params to use for later models.\n",
    "# done like this with variable alias because I previously hand-copied\n",
    "# the params to a separate dictionary and needed the rfc_params variable for\n",
    "# that dictionary\n",
    "rfc_params = gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b123faac-bb0d-4e5a-8320-02e0cf449423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.7885586924219911\n",
      "Model Test Score (best): 0.6601307189542484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on body text only - use same best params from gridsearch\n",
    "body_rfc = RandomForestClassifier(**rfc_params)\n",
    "body_rfc.fit(train_body_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(body_rfc, \n",
    "                            (train_body_cv, y_train), \n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3cd63ce8-a88c-4183-a000-6f53caa57c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.837592867756315\n",
      "Model Test Score (best): 0.7011289364230541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on all text\n",
    "alltext_rfc = RandomForestClassifier(**rfc_params)\n",
    "alltext_rfc.fit(train_alltext_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(alltext_rfc, \n",
    "                            (train_alltext_cv, y_train), \n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6edc7-132a-4475-bb2d-a00a84a517d2",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2179dc31-60cf-4e36-bbce-360d51481ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.66      0.62      0.64       854\n",
      "         low       0.63      0.67      0.65       829\n",
      "\n",
      "    accuracy                           0.64      1683\n",
      "   macro avg       0.64      0.64      0.64      1683\n",
      "weighted avg       0.64      0.64      0.64      1683\n",
      "\n",
      "True Positives: 552\n",
      "True Negatives: 530\n",
      "False Positives: 324\n",
      "False Negatives: 277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# title words\n",
    "print(ipyutils.metrics_report(gs.best_estimator_, y_test, test_title_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed8e8a93-fe21-46be-89e5-0b812b2ff8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.70      0.58      0.63       854\n",
      "         low       0.63      0.75      0.68       829\n",
      "\n",
      "    accuracy                           0.66      1683\n",
      "   macro avg       0.67      0.66      0.66      1683\n",
      "weighted avg       0.67      0.66      0.66      1683\n",
      "\n",
      "True Positives: 619\n",
      "True Negatives: 492\n",
      "False Positives: 362\n",
      "False Negatives: 210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# body words\n",
    "print(ipyutils.metrics_report(body_rfc, y_test, test_body_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14307311-65b9-4473-b0d4-d5fd5b03a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.72      0.68      0.70       854\n",
      "         low       0.69      0.72      0.70       829\n",
      "\n",
      "    accuracy                           0.70      1683\n",
      "   macro avg       0.70      0.70      0.70      1683\n",
      "weighted avg       0.70      0.70      0.70      1683\n",
      "\n",
      "True Positives: 598\n",
      "True Negatives: 582\n",
      "False Positives: 272\n",
      "False Negatives: 231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all words\n",
    "print(ipyutils.metrics_report(alltext_rfc, y_test, test_alltext_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40edadf-bd04-47eb-966b-d9309c265025",
   "metadata": {},
   "source": [
    "#### Analysis of Random Forest Classifier Score\n",
    "\n",
    "Perhaps unsurprisingly, analyzing on the full text (body plus title) gave better prediction accuracy. However, for purposes of the problem statement, the title and body are possibly best kept separate, as reddit does not diplay the full body text by default, and searches only display titles. If we are looking for maximum engagement, we are more likely to reach the most number of users via the post titles rather than the post bodies.\n",
    "\n",
    "Accuracy is better than baseline by 14-20 percentage points depending on the type of text field used. Since we are looking to increase engagement, the metrics concerning the quality of our positive outcomes are probably more important. Here, precision was higher for the high-engagement category, whereas recall was higher for the low-engagement category. In the alltext test, for example, the model correctly predicted high-engagement category 72% of the time, but only correctly predicted 68% of all high-engagement posts.\n",
    "\n",
    "The model is overfit (which is probably to be expected from a decision-tree-based model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99bf60-d9a8-44e4-8cb7-d15db687edda",
   "metadata": {},
   "source": [
    "#### Exploration of Model Results - Title Predictors\n",
    "\n",
    "Or: what words were best predictors in the titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a4c66b7-d1bd-4a8b-943e-b373daa88f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pct</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>diff</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>21</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>15</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascendant</th>\n",
       "      <td>18</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placement</th>\n",
       "      <td>27</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagittarius</th>\n",
       "      <td>17</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone else</th>\n",
       "      <td>19</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>19</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>born</th>\n",
       "      <td>20</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiron</th>\n",
       "      <td>15</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun moon</th>\n",
       "      <td>15</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>15</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saturn return</th>\n",
       "      <td>25</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>29</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capricorn</th>\n",
       "      <td>37</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>28</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               total       pct  correct  incorrect  diff  tp  tn  fp  fn  \\\n",
       "way               21  0.002697       20          1    19  11   9   0   1   \n",
       "node              15  0.001927       14          1    13   8   6   1   0   \n",
       "ascendant         18  0.002312       16          2    14  11   5   2   0   \n",
       "placement         27  0.003468       24          3    21  22   2   2   1   \n",
       "sagittarius       17  0.002183       15          2    13  13   2   2   0   \n",
       "anyone else       19  0.002440       16          3    13  14   2   3   0   \n",
       "really            19  0.002440       16          3    13  10   6   2   1   \n",
       "born              20  0.002569       16          4    12   9   7   1   3   \n",
       "chiron            15  0.001927       12          3     9   8   4   2   1   \n",
       "sun moon          15  0.001927       12          3     9   9   3   3   0   \n",
       "talk              15  0.001927       12          3     9   9   3   1   2   \n",
       "saturn return     25  0.003211       19          6    13  15   4   6   0   \n",
       "think             29  0.003725       22          7    15  17   5   4   3   \n",
       "capricorn         37  0.004752       28          9    19  24   4   7   2   \n",
       "much              28  0.003596       21          7    14  12   9   5   2   \n",
       "\n",
       "               accuracy    recall  specificity  precision        f1  \n",
       "way            0.952381  0.916667     1.000000   1.000000  0.956522  \n",
       "node           0.933333  1.000000     0.857143   0.888889  0.941176  \n",
       "ascendant      0.888889  1.000000     0.714286   0.846154  0.916667  \n",
       "placement      0.888889  0.956522     0.500000   0.916667  0.936170  \n",
       "sagittarius    0.882353  1.000000     0.500000   0.866667  0.928571  \n",
       "anyone else    0.842105  1.000000     0.400000   0.823529  0.903226  \n",
       "really         0.842105  0.909091     0.750000   0.833333  0.869565  \n",
       "born           0.800000  0.750000     0.875000   0.900000  0.818182  \n",
       "chiron         0.800000  0.888889     0.666667   0.800000  0.842105  \n",
       "sun moon       0.800000  1.000000     0.500000   0.750000  0.857143  \n",
       "talk           0.800000  0.818182     0.750000   0.900000  0.857143  \n",
       "saturn return  0.760000  1.000000     0.400000   0.714286  0.833333  \n",
       "think          0.758621  0.850000     0.555556   0.809524  0.829268  \n",
       "capricorn      0.756757  0.923077     0.363636   0.774194  0.842105  \n",
       "much           0.750000  0.857143     0.642857   0.705882  0.774194  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title exploration - what words were best predictors in the titles?\n",
    "\n",
    "# get predictions\n",
    "title_preds_test = gs.best_estimator_.predict(test_title_cv)\n",
    "\n",
    "# make dataframe from CountVectorizer sparse matrix\n",
    "Xdf = pd.DataFrame(test_title_cv.A, \n",
    "                   columns=cv_title.get_feature_names_out(),\n",
    "                   index=y_test.index)\n",
    "\n",
    "# get metrics per word (see custom script ipynb_utils.py)\n",
    "wc_df = ipyutils.wc_metrics(Xdf, y_test, title_preds_test, opts=[])\n",
    "\n",
    "# filters - high word count, high accuracy, high recall\n",
    "high_wc_filt = (wc_df['total'] > wc_df['total'].quantile(0.75))\n",
    "high_accuracy_filt = (wc_df['accuracy'] >= 0.75)\n",
    "high_recall_filt = (wc_df['recall'] >= 0.75)\n",
    "\n",
    "# get results\n",
    "wc_df[high_wc_filt & high_accuracy_filt & high_recall_filt].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27442e5-c6ac-4987-b944-39281c462b4b",
   "metadata": {},
   "source": [
    "#### Analysis of Metrics\n",
    "\n",
    "The above chart is compiled information from the words in the data set. Filters were created to select documents based on correct and incorrect predictions, among other metrics (see ipynb_utils.py script). The features (word counts) were then summed to get word counts per metric, and various other metrics were derived. This way these metrics could be explored on a word-by-word basis.\n",
    "\n",
    "The above chart is sorted by accuracy score (high-to-low) and only shows words with total count in the 75th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5af52e-7092-49ef-ada1-ae8e4d2a0980",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Other Classifiers Comparison\n",
    "\n",
    "I am comparing various other classifiers to see how general scores compare. Will select a second to use as a comparison classifier for future modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ba260-eecb-48b6-8f99-ec788f991e1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "425ad43f-4764-4b0f-9b4a-9119a9bd68cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Model Train Score (best): 0.7242199108469539\n",
      "Model Test Score (best): 0.6399286987522281\n",
      "Model Best Estimator: ExtraTreesClassifier(min_impurity_decrease=0.0001, min_samples_leaf=5,\n",
      "                     min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                     random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_etc = ExtraTreesClassifier()\n",
    "# use same gs_params from random forest\n",
    "title_etc_gs = GridSearchCV(title_etc, gs_params, verbose=1, n_jobs=-1)\n",
    "title_etc_gs.fit(train_title_cv, y_train)\n",
    "print(ipyutils.score_report(title_etc_gs,\n",
    "                            (train_title_cv, y_train),\n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7dede69f-bccc-48dd-9e35-2005909d76b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etc_params = title_etc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "99b33d6a-50dd-4417-a58f-d019032a12cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.787518573551263\n",
      "Model Test Score (best): 0.6708259061200238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_etc = ExtraTreesClassifier(**etc_params)\n",
    "body_etc.fit(train_body_cv, y_train)\n",
    "print(ipyutils.score_report(body_etc,\n",
    "                            (train_body_cv, y_train),\n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f93d52f9-84d7-4018-adeb-e1e05c4fbc46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.8346210995542348\n",
      "Model Test Score (best): 0.6898395721925134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alltext_etc = ExtraTreesClassifier(**etc_params)\n",
    "alltext_etc.fit(train_alltext_cv, y_train)\n",
    "print(ipyutils.score_report(alltext_etc,\n",
    "                            (train_alltext_cv, y_train),\n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1a46-a11f-443c-a1df-9ce896ce34ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Analysis of Extra Trees Classifier Score\n",
    "\n",
    "ExtraTrees performed slightly worse than Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42df3-ce1d-4a10-ba00-c8c6879bcc0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bcd52c68-5cc8-4177-bdcd-bda851966f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6705794947994056, 0.6102198455139631)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost\n",
    "ada = AdaBoostClassifier(random_state=1)\n",
    "ada.fit(train_alltext_cv, y_train)\n",
    "ada.score(train_alltext_cv, y_train), ada.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c261c-ce73-445e-ab00-0c9114ebcb17",
   "metadata": {},
   "source": [
    "#### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c22ad6f8-d1c7-4621-80db-fc024a28763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7306092124814264, 0.6500297088532383)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boost\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(train_alltext_cv, y_train)\n",
    "gb.score(train_alltext_cv, y_train), gb.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2cfc07-2527-41db-a0ea-96027c1e1611",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d0ae404-9996-4796-8c15-3ea2b9eae457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7057949479940565, 0.5692216280451574)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbors\n",
    "knc = KNeighborsClassifier(5)\n",
    "knc.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb2823-4122-4167-a33b-d4739ada0e9a",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c1be38a-e5ea-425c-b15d-ca9fb6ab357e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7057949479940565, 0.5692216280451574)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64582d99-c203-4bf5-9892-4f04d3505f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2deab815-a991-4d89-b283-a5a441273165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7156017830609213, 0.6500297088532383)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_alltext_cv, y_train)\n",
    "mnb.score(train_alltext_cv, y_train), mnb.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a3678-2005-4494-9218-147afcbdb87e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Analysis of Other Classifiers on Word Vectors\n",
    "\n",
    "Naive Bayes and Gradient Boost were tied on the test set. Other models were weaker performers. Due to less overfitting on Naive Bayes I will use that for future model comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b24f9-6edb-4c2d-9e81-da91c969002a",
   "metadata": {},
   "source": [
    "### 4a. Other Features\n",
    "\n",
    "There are a few other features I'd like to explore (word/character counts, for example).\n",
    "\n",
    "Date/time features might not be appropriate here due to how Reddit works and the scraping process. Reddit no longer allows search by date, so I cannot get consecutive posts over time, and I am therefore trying to get as many posts I can via searches for words. Therefore, the post distribution over time that I get from my scrapes may not be the same as the actual post distribution over time, and there is no way to verify this with my current scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebaa4027-9d3e-480f-9a87-15f22ffd402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'title', 'body-text', 'title-cc', 'title-wc', 'body-cc',\n",
       "       'body-wc', 'media', 'comments', 'comments_gt_median', 'day', 'month',\n",
       "       'weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cad91f97-59d4-40dc-8e59-0d3971d358c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_gt_median</th>\n",
       "      <th>month</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "      <td>2858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  title  body-text  title-cc  title-wc  body-cc  body-wc  media  \\\n",
       "day                                                                        \n",
       "0     698    698        698       698       698      698      698    698   \n",
       "1     584    584        584       584       584      584      584    584   \n",
       "2    1195   1195       1195      1195      1195     1195     1195   1195   \n",
       "3    1080   1080       1080      1080      1080     1080     1080   1080   \n",
       "4     986    986        986       986       986      986      986    986   \n",
       "5    2858   2858       2858      2858      2858     2858     2858   2858   \n",
       "6    1012   1012       1012      1012      1012     1012     1012   1012   \n",
       "\n",
       "     comments  comments_gt_median  month  weekend  \n",
       "day                                                \n",
       "0         698                 698    698      698  \n",
       "1         584                 584    584      584  \n",
       "2        1195                1195   1195     1195  \n",
       "3        1080                1080   1080     1080  \n",
       "4         986                 986    986      986  \n",
       "5        2858                2858   2858     2858  \n",
       "6        1012                1012   1012     1012  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('day').count() # decent spread, probably enough to be OK with here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e4ab1b63-e1cc-4bb9-a5f2-329e62d52023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_gt_median</th>\n",
       "      <th>day</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "      <td>5637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  title  body-text  title-cc  title-wc  body-cc  body-wc  media  \\\n",
       "month                                                                        \n",
       "1       232    232        232       232       232      232      232    232   \n",
       "2       211    211        211       211       211      211      211    211   \n",
       "3       221    221        221       221       221      221      221    221   \n",
       "4       227    227        227       227       227      227      227    227   \n",
       "5       233    233        233       233       233      233      233    233   \n",
       "6       175    175        175       175       175      175      175    175   \n",
       "7       213    213        213       213       213      213      213    213   \n",
       "8       371    371        371       371       371      371      371    371   \n",
       "9      5637   5637       5637      5637      5637     5637     5637   5637   \n",
       "10      503    503        503       503       503      503      503    503   \n",
       "11      201    201        201       201       201      201      201    201   \n",
       "12      189    189        189       189       189      189      189    189   \n",
       "\n",
       "       comments  comments_gt_median   day  weekend  \n",
       "month                                               \n",
       "1           232                 232   232      232  \n",
       "2           211                 211   211      211  \n",
       "3           221                 221   221      221  \n",
       "4           227                 227   227      227  \n",
       "5           233                 233   233      233  \n",
       "6           175                 175   175      175  \n",
       "7           213                 213   213      213  \n",
       "8           371                 371   371      371  \n",
       "9          5637                5637  5637     5637  \n",
       "10          503                 503   503      503  \n",
       "11          201                 201   201      201  \n",
       "12          189                 189   189      189  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('month').count() # what's with september???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a718e-2a72-4892-acfc-5d7e505ba219",
   "metadata": {},
   "source": [
    "#### Word- and Character-counts and Media Indicator\n",
    "\n",
    "I will take a brute-force approach and do a quick model on a lot of different feature sets and combinations, and select ones to take a closer look at based on model scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7209ab69-89ce-422d-8659-6a537d08ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to test all of the following feature combinations just to see if\n",
    "# they show any major differences\n",
    "col_opts = [\n",
    "    ['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc'],\n",
    "    ['media'],\n",
    "    ['title-cc', 'title-wc'],\n",
    "    ['body-cc', 'body-wc'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc'],\n",
    "    ['day'],\n",
    "    ['month'],\n",
    "    ['day', 'month'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day', 'month']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b536dcd9-e057-46b3-b2f6-5f43e5983b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain: 0.8239227340267459\n",
      "\ttest: 0.6226975638740344\n",
      "['media']\n",
      "\ttrain: 0.5545319465081724\n",
      "\ttest: 0.5472370766488414\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain: 0.6208023774145617\n",
      "\ttest: 0.5561497326203209\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain: 0.6910846953937593\n",
      "\ttest: 0.5430778371954843\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain: 0.8460624071322437\n",
      "\ttest: 0.5870469399881164\n",
      "['day']\n",
      "\ttrain: 0.5671619613670134\n",
      "\ttest: 0.5680332739156269\n",
      "['month']\n",
      "\ttrain: 0.5221396731054978\n",
      "\ttest: 0.5086155674390969\n",
      "['day', 'month']\n",
      "\ttrain: 0.6022288261515601\n",
      "\ttest: 0.5941770647653001\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain: 0.8527488855869242\n",
      "\ttest: 0.6030897207367796\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day', 'month']\n",
      "\ttrain: 0.8514115898959881\n",
      "\ttest: 0.6125965537730244\n"
     ]
    }
   ],
   "source": [
    "# loop over each feature combination and run a model\n",
    "for opt in col_opts:\n",
    "    xrfc = RandomForestClassifier(**rfc_params)\n",
    "    xrfc.fit(X_train[opt], y_train)\n",
    "    print(f'{opt}\\n\\ttrain: {xrfc.score(X_train[opt], y_train)}'\\\n",
    "          + f'\\n\\ttest: {xrfc.score(X_test[opt], y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "991dcc41-103b-460b-9cc2-48e71dfccb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6730, 593) (1683, 593)\n",
      "(6730, 589) (1683, 589)\n",
      "(6730, 590) (1683, 590)\n",
      "(6730, 590) (1683, 590)\n",
      "(6730, 592) (1683, 592)\n",
      "(6730, 589) (1683, 589)\n",
      "(6730, 589) (1683, 589)\n",
      "(6730, 590) (1683, 590)\n",
      "(6730, 593) (1683, 593)\n",
      "(6730, 594) (1683, 594)\n"
     ]
    }
   ],
   "source": [
    "# now let's do the same but adding the Vectorized title\n",
    "\n",
    "# make vectorized title dataframes\n",
    "train_title_cv_df = ipyutils.df_from_cv(cv_title, train_title_cv, X_train.index)\n",
    "test_title_cv_df = ipyutils.df_from_cv(cv_title, test_title_cv, X_test.index)\n",
    "\n",
    "# concat all column combos to vectorized title dataframes\n",
    "combo_dfs = list()\n",
    "for opt in col_opts:\n",
    "    # 0 is train, 1 is test\n",
    "    combo_dfs.append((ipyutils.easy_concat(X_train[opt], train_title_cv_df),\n",
    "                      ipyutils.easy_concat(X_test[opt], test_title_cv_df)))\n",
    "\n",
    "# check for integrity\n",
    "for cdf in combo_dfs:\n",
    "    print(cdf[0].shape, cdf[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "941acabc-f0f9-4fc1-9da7-bed61b138cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain:0.7579494799405646\n",
      "\ttest:0.6743909685086156\n",
      "['media']\n",
      "\ttrain:0.7392273402674592\n",
      "\ttest:0.6512180629827689\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain:0.736552748885587\n",
      "\ttest:0.6339869281045751\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain:0.7401188707280832\n",
      "\ttest:0.6530005941770648\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain:0.7527488855869242\n",
      "\ttest:0.6589423648247178\n",
      "['day']\n",
      "\ttrain:0.7378900445765231\n",
      "\ttest:0.6446821152703506\n",
      "['month']\n",
      "\ttrain:0.7323922734026745\n",
      "\ttest:0.6428995840760546\n",
      "['day', 'month']\n",
      "\ttrain:0.7445765230312036\n",
      "\ttest:0.6642899584076055\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain:0.7557206537890044\n",
      "\ttest:0.6654783125371361\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day', 'month']\n",
      "\ttrain:0.7610698365527488\n",
      "\ttest:0.6714200831847891\n"
     ]
    }
   ],
   "source": [
    "# run a model on each combo\n",
    "for ix, cdf in enumerate(combo_dfs):\n",
    "    opt = col_opts[ix]\n",
    "    xrfc.fit(cdf[0], y_train)\n",
    "    print(f'{opt}\\n\\ttrain:{xrfc.score(cdf[0], y_train)}\\n'\\\n",
    "          + f'\\ttest:{xrfc.score(cdf[1], y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9ec7fd55-5def-492e-a299-d81a244c7fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7579494799405646, 0.6743909685086156)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# media + word/char counts seem to have most impact. \n",
    "# What are the stats?\n",
    "\n",
    "# re-get score on [media + wc/cc + title_cv]\n",
    "media_train = combo_dfs[0][0]\n",
    "media_test = combo_dfs[0][1]\n",
    "\n",
    "media_rfc = RandomForestClassifier(**rfc_params)\n",
    "media_rfc.fit(media_train, y_train)\n",
    "media_rfc.score(media_train, y_train), media_rfc.score(media_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d99bedd-34f8-4fbc-a5ec-a20c29e1bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69       854\n",
      "           1       0.68      0.65      0.66       829\n",
      "\n",
      "    accuracy                           0.67      1683\n",
      "   macro avg       0.67      0.67      0.67      1683\n",
      "weighted avg       0.67      0.67      0.67      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get report on predictions for [media + wc/cc + title_cv]\n",
    "media_preds_test = media_rfc.predict(media_test)\n",
    "print(classification_report(y_test, media_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fe997802-c778-49c5-a6fc-a0925b8f76bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1683, 6730]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [157]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m media_rfc\u001b[38;5;241m.\u001b[39mfit(X_train[col_opts[\u001b[38;5;241m0\u001b[39m]], y_train)\n\u001b[1;32m      4\u001b[0m media_preds_test \u001b[38;5;241m=\u001b[39m media_rfc\u001b[38;5;241m.\u001b[39mpredict(X_train[col_opts[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmedia_preds_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2125\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   2011\u001b[0m     y_true,\n\u001b[1;32m   2012\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2020\u001b[0m ):\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \n\u001b[1;32m   2023\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2125\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1683, 6730]"
     ]
    }
   ],
   "source": [
    "# get report on [media + wc/cc] only\n",
    "media_rfc = RandomForestClassifier(**rfc_params)\n",
    "media_rfc.fit(X_train[col_opts[0]], y_train)\n",
    "media_preds_test = media_rfc.predict(X_train[col_opts[0]])\n",
    "print(classification_report(y_test, media_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96814060-f3a2-40f4-b1a4-1c7f65a229fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where media exists, there is no body text\n",
    "df.loc[(df['media']==1) & (df['body-text'] != ''), ['media','body-text']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872cb055-8a93-4e1d-8e3e-85dfc1622ac9",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "From what I've seen so far, adding vectorized text data seems to even out the model a bit, with less overfitting than when using just word- and character-count features.\n",
    "\n",
    "Here I was only using vectorized words from title fields. It is interesting that of all the additional features, the *media* feature (which states whether or not media such as images and video are in the post) is the most impactful in the absence of all others.\n",
    "\n",
    "This begs the question, would a better predictor be a predictor on body text with media added, since it seems like media is an alternate body text type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bb283-c546-4a0a-ac24-9889282eccce",
   "metadata": {},
   "source": [
    "#### Exploring Media and Body Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cb4e2d6-c425-43fc-b550-eed4a8718e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized body sets: train_body_cv, test_body_cv\n",
    "# Vectorized title sets: train_title_cv, test_title_cv\n",
    "# Vectorized alltext sets: train_alltext_cv, test_alltext_cv\n",
    "# Train media set: X_train['media']\n",
    "\n",
    "train_body_cvdf = ipyutils.df_from_cv(cv_body, train_body_cv, y_train.index)\n",
    "test_body_cvdf = ipyutils.df_from_cv(cv_body, test_body_cv, y_test.index)\n",
    "\n",
    "train_media_df = X_train[['media']]\n",
    "test_media_df = X_test[['media']]\n",
    "\n",
    "# get titles for future exploration\n",
    "train_title_cvdf = ipyutils.df_from_cv(cv_title, train_title_cv, y_train.index)\n",
    "test_title_cvdf = ipyutils.df_from_cv(cv_title, test_title_cv, y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd04bdfd-bc72-415d-bdd2-af4436d911db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      3417\n",
      "           1       0.85      0.71      0.77      3313\n",
      "\n",
      "    accuracy                           0.79      6730\n",
      "   macro avg       0.80      0.79      0.79      6730\n",
      "weighted avg       0.80      0.79      0.79      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69       854\n",
      "           1       0.68      0.60      0.64       829\n",
      "\n",
      "    accuracy                           0.67      1683\n",
      "   macro avg       0.67      0.67      0.67      1683\n",
      "weighted avg       0.67      0.67      0.67      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine body text and media tables\n",
    "train_bodymedia_df = ipyutils.easy_concat(train_media_df, train_body_cvdf)\n",
    "test_bodymedia_df = ipyutils.easy_concat(test_media_df, test_body_cvdf)\n",
    "\n",
    "bodymedia_rfc = RandomForestClassifier(**rfc_params)\n",
    "bodymedia_rfc.fit(train_bodymedia_df, y_train)\n",
    "bodymedia_train_preds = bodymedia_rfc.predict(train_bodymedia_df)\n",
    "bodymedia_test_preds = bodymedia_rfc.predict(test_bodymedia_df)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, bodymedia_train_preds), \n",
    "      \"TEST\\n\", classification_report(y_test, bodymedia_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "171ce80c-3358-4b52-b488-efb31ab6187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      3417\n",
      "           1       0.76      0.68      0.72      3313\n",
      "\n",
      "    accuracy                           0.74      6730\n",
      "   macro avg       0.74      0.74      0.74      6730\n",
      "weighted avg       0.74      0.74      0.74      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67       854\n",
      "           1       0.66      0.62      0.64       829\n",
      "\n",
      "    accuracy                           0.66      1683\n",
      "   macro avg       0.66      0.66      0.66      1683\n",
      "weighted avg       0.66      0.66      0.66      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can we do better with a different model?\n",
    "bodymedia_nb = MultinomialNB()\n",
    "bodymedia_nb.fit(train_bodymedia_df, y_train)\n",
    "bodymedia_train_preds = bodymedia_nb.predict(train_bodymedia_df)\n",
    "bodymedia_test_preds = bodymedia_nb.predict(test_bodymedia_df)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, bodymedia_train_preds),\n",
    "      \"TEST\\n\", classification_report(y_test, bodymedia_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44da3d4e-9b4a-48e2-9aaa-b749eeb18fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71      3417\n",
      "           1       0.71      0.57      0.63      3313\n",
      "\n",
      "    accuracy                           0.68      6730\n",
      "   macro avg       0.68      0.67      0.67      6730\n",
      "weighted avg       0.68      0.68      0.67      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       854\n",
      "           1       0.65      0.52      0.58       829\n",
      "\n",
      "    accuracy                           0.62      1683\n",
      "   macro avg       0.63      0.62      0.62      1683\n",
      "weighted avg       0.63      0.62      0.62      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or a different model?\n",
    "bodymedia_boost = AdaBoostClassifier()\n",
    "bodymedia_boost.fit(train_bodymedia_df, y_train)\n",
    "bodymedia_train_preds = bodymedia_boost.predict(train_bodymedia_df)\n",
    "bodymedia_test_preds = bodymedia_boost.predict(test_bodymedia_df)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, bodymedia_train_preds),\n",
    "      \"TEST\\n\", classification_report(y_test, bodymedia_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f39e658a-96ea-414f-a277-b2486d727975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(title) 10', '(title) 10th', '(title) 10th house', '(title) 11',\n",
       "       '(title) 11th', '(title) 11th house', '(title) 12', '(title) 12h',\n",
       "       '(title) 12th', '(title) 12th house'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, do one more test taking into account title words, body words, and media\n",
    "\n",
    "# First prefix title and body words with title and body, respectively\n",
    "train_title_cvdf = train_title_cvdf.add_prefix('(title) ')\n",
    "train_body_cvdf = train_body_cvdf.add_prefix('(body) ')\n",
    "test_title_cvdf = test_title_cvdf.add_prefix('(title) ')\n",
    "test_body_cvdf = test_body_cvdf.add_prefix('(body) ')\n",
    "train_title_cvdf.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b40131b5-1bff-46d2-9215-8bb4d4d9c0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6730, 7052), (1683, 7052), (6730,), (1683,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make combination tables of media indicator, title words, and body words\n",
    "train_megadf = pd.concat([train_media_df, train_title_cvdf, train_body_cvdf], axis=1)\n",
    "test_megadf = pd.concat([test_media_df, test_title_cvdf, test_body_cvdf], axis=1)\n",
    "train_megadf.shape, test_megadf.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef0b51bd-e43f-4120-bdea-3ca10a22f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83      3417\n",
      "           1       0.85      0.79      0.82      3313\n",
      "\n",
      "    accuracy                           0.83      6730\n",
      "   macro avg       0.83      0.83      0.83      6730\n",
      "weighted avg       0.83      0.83      0.83      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       854\n",
      "           1       0.71      0.70      0.70       829\n",
      "\n",
      "    accuracy                           0.71      1683\n",
      "   macro avg       0.71      0.71      0.71      1683\n",
      "weighted avg       0.71      0.71      0.71      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run a Random Forest model\n",
    "mega_rfc = RandomForestClassifier(**rfc_params)\n",
    "mega_rfc.fit(train_megadf, y_train)\n",
    "mega_train_preds = mega_rfc.predict(train_megadf)\n",
    "mega_test_preds = mega_rfc.predict(test_megadf)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, mega_train_preds),\n",
    "      \"TEST\\n\", classification_report(y_test, mega_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96ba7747-314f-4b9c-98e5-f4329a4add5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      3417\n",
      "           1       0.77      0.73      0.75      3313\n",
      "\n",
      "    accuracy                           0.76      6730\n",
      "   macro avg       0.76      0.76      0.76      6730\n",
      "weighted avg       0.76      0.76      0.76      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       854\n",
      "           1       0.67      0.65      0.66       829\n",
      "\n",
      "    accuracy                           0.67      1683\n",
      "   macro avg       0.67      0.67      0.67      1683\n",
      "weighted avg       0.67      0.67      0.67      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run a Naive Bayes model\n",
    "mega_nb = MultinomialNB()\n",
    "mega_nb.fit(train_megadf, y_train)\n",
    "mega_train_preds = mega_nb.predict(train_megadf)\n",
    "mega_test_preds = mega_nb.predict(test_megadf)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, mega_train_preds),\n",
    "      \"TEST\\n\", classification_report(y_test, mega_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07d1b645-8708-42fd-9508-db65f8cf4cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      3417\n",
      "           1       0.74      0.64      0.68      3313\n",
      "\n",
      "    accuracy                           0.71      6730\n",
      "   macro avg       0.71      0.71      0.71      6730\n",
      "weighted avg       0.71      0.71      0.71      6730\n",
      " TEST\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       854\n",
      "           1       0.66      0.59      0.62       829\n",
      "\n",
      "    accuracy                           0.65      1683\n",
      "   macro avg       0.65      0.65      0.65      1683\n",
      "weighted avg       0.65      0.65      0.65      1683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run Ada Boost\n",
    "mega_ada = AdaBoostClassifier(n_estimators=100)\n",
    "mega_ada.fit(train_megadf, y_train)\n",
    "mega_train_preds = mega_ada.predict(train_megadf)\n",
    "mega_test_preds = mega_ada.predict(test_megadf)\n",
    "print(\"TRAIN\\n\", classification_report(y_train, mega_train_preds),\n",
    "      \"TEST\\n\", classification_report(y_test, mega_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59deaa-9621-4038-98f7-678bf34ce555",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "The combining of body text, title text, and media indicator got me the highest score so far of over 70% accuracy on the test set. These results were from the Random Forest classifier, which has consistently outperformed all others on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76469b4c-4831-494c-863b-f6e9724070d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_rfc.fit(train_megadf, y_train)\n",
    "mega_train_preds = mega_rfc.predict(train_megadf)\n",
    "mega_test_preds = mega_rfc.predict(test_megadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddae5660-a8be-474b-ae2e-48a1c0fb3036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pct</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>diff</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(body) figure</th>\n",
       "      <td>79</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) vs</th>\n",
       "      <td>58</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) native</th>\n",
       "      <td>73</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.948148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) soul</th>\n",
       "      <td>69</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) lol</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.898551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) father</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.913386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) ideas</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) 8th house</th>\n",
       "      <td>73</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) emotions</th>\n",
       "      <td>60</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) later</th>\n",
       "      <td>57</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) thoughts</th>\n",
       "      <td>106</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>53</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) attention</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.867470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(title) aspects</th>\n",
       "      <td>74</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) put</th>\n",
       "      <td>63</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) whatever</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) sun sign</th>\n",
       "      <td>67</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) trying</th>\n",
       "      <td>92</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) ruled</th>\n",
       "      <td>51</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) keep</th>\n",
       "      <td>76</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(body) heard</th>\n",
       "      <td>53</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.830769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  total       pct  correct  incorrect  diff  tp  tn  fp  fn  \\\n",
       "(body) figure        79  0.000700       73          6    67  61  12   2   4   \n",
       "(body) vs            58  0.000514       53          5    48  13  40   3   2   \n",
       "(body) native        73  0.000647       66          7    59  64   2   6   1   \n",
       "(body) soul          69  0.000612       60          9    51  24  36   2   7   \n",
       "(body) lol           52  0.000461       45          7    38  31  14   4   3   \n",
       "(body) father        75  0.000665       64         11    53  58   6  10   1   \n",
       "(body) ideas         52  0.000461       44          8    36  26  18   5   3   \n",
       "(body) 8th house     73  0.000647       61         12    49  51  10   9   3   \n",
       "(body) emotions      60  0.000532       50         10    40  34  16  10   0   \n",
       "(body) later         57  0.000505       47         10    37  17  30   7   3   \n",
       "(body) thoughts     106  0.000940       87         19    68  53  34  10   9   \n",
       "(body) attention     59  0.000523       48         11    37  36  12   5   6   \n",
       "(title) aspects      74  0.000656       60         14    46  29  31   6   8   \n",
       "(body) put           63  0.000559       51         12    39  25  26   6   6   \n",
       "(body) whatever      52  0.000461       42         10    32  30  12   6   4   \n",
       "(body) sun sign      67  0.000594       54         13    41  43  11   8   5   \n",
       "(body) trying        92  0.000816       74         18    56  38  36   9   9   \n",
       "(body) ruled         51  0.000452       41         10    31  32   9   7   3   \n",
       "(body) keep          76  0.000674       61         15    46  35  26  10   5   \n",
       "(body) heard         53  0.000470       42         11    31  27  15   7   4   \n",
       "\n",
       "                  accuracy    recall  specificity  precision        f1  \n",
       "(body) figure     0.924051  0.938462     0.857143   0.968254  0.953125  \n",
       "(body) vs         0.913793  0.866667     0.930233   0.812500  0.838710  \n",
       "(body) native     0.904110  0.984615     0.250000   0.914286  0.948148  \n",
       "(body) soul       0.869565  0.774194     0.947368   0.923077  0.842105  \n",
       "(body) lol        0.865385  0.911765     0.777778   0.885714  0.898551  \n",
       "(body) father     0.853333  0.983051     0.375000   0.852941  0.913386  \n",
       "(body) ideas      0.846154  0.896552     0.782609   0.838710  0.866667  \n",
       "(body) 8th house  0.835616  0.944444     0.526316   0.850000  0.894737  \n",
       "(body) emotions   0.833333  1.000000     0.615385   0.772727  0.871795  \n",
       "(body) later      0.824561  0.850000     0.810811   0.708333  0.772727  \n",
       "(body) thoughts   0.820755  0.854839     0.772727   0.841270  0.848000  \n",
       "(body) attention  0.813559  0.857143     0.705882   0.878049  0.867470  \n",
       "(title) aspects   0.810811  0.783784     0.837838   0.828571  0.805556  \n",
       "(body) put        0.809524  0.806452     0.812500   0.806452  0.806452  \n",
       "(body) whatever   0.807692  0.882353     0.666667   0.833333  0.857143  \n",
       "(body) sun sign   0.805970  0.895833     0.578947   0.843137  0.868687  \n",
       "(body) trying     0.804348  0.808511     0.800000   0.808511  0.808511  \n",
       "(body) ruled      0.803922  0.914286     0.562500   0.820513  0.864865  \n",
       "(body) keep       0.802632  0.875000     0.722222   0.777778  0.823529  \n",
       "(body) heard      0.792453  0.870968     0.681818   0.794118  0.830769  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make my metrics dataframe\n",
    "metrics_df = ipyutils.wc_metrics(test_megadf, y_test, mega_test_preds)\n",
    "\n",
    "# set up filters\n",
    "high_wc_filt = (metrics_df['total'] > 50)\n",
    "high_accuracy_filt = (metrics_df['accuracy'] >= 0.75)\n",
    "high_recall_filt = (metrics_df['recall'] >= 0.75)\n",
    "\n",
    "# view results\n",
    "metrics_df[high_wc_filt & high_accuracy_filt & high_recall_filt].sort_values(by='accuracy', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba82f31-612b-4161-ad87-a6430da8a3bc",
   "metadata": {},
   "source": [
    "#### Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f921e5d3-09c2-4a2d-8c1d-f44b4d9c165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>698.0</td>\n",
       "      <td>37.614613</td>\n",
       "      <td>44.911348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584.0</td>\n",
       "      <td>28.755137</td>\n",
       "      <td>45.766167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195.0</td>\n",
       "      <td>30.141423</td>\n",
       "      <td>47.413106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080.0</td>\n",
       "      <td>57.019444</td>\n",
       "      <td>138.504473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>64.25</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>986.0</td>\n",
       "      <td>28.988844</td>\n",
       "      <td>53.898804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2858.0</td>\n",
       "      <td>24.478307</td>\n",
       "      <td>71.773233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1012.0</td>\n",
       "      <td>31.366601</td>\n",
       "      <td>44.111640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       mean         std  min   25%   50%    75%     max\n",
       "day                                                               \n",
       "0     698.0  37.614613   44.911348  0.0  10.0  22.0  48.00   442.0\n",
       "1     584.0  28.755137   45.766167  0.0   6.0  14.0  31.00   561.0\n",
       "2    1195.0  30.141423   47.413106  0.0   6.5  14.0  35.00   507.0\n",
       "3    1080.0  57.019444  138.504473  0.0   9.0  25.0  64.25  3100.0\n",
       "4     986.0  28.988844   53.898804  0.0   6.0  13.0  31.00  1075.0\n",
       "5    2858.0  24.478307   71.773233  0.0   5.0  11.0  25.00  3138.0\n",
       "6    1012.0  31.366601   44.111640  0.0   6.0  15.0  39.00   596.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('day')['comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bde61-66ab-4a60-abbd-2e3d7be01c9f",
   "metadata": {},
   "source": [
    "**NOTES** Thursday seems to be a hot day for comments, with a much higher mean, median, and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7324461-171a-4987-9641-180857654837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232.0</td>\n",
       "      <td>35.155172</td>\n",
       "      <td>46.704673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211.0</td>\n",
       "      <td>35.037915</td>\n",
       "      <td>55.930386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221.0</td>\n",
       "      <td>28.384615</td>\n",
       "      <td>40.605771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227.0</td>\n",
       "      <td>23.092511</td>\n",
       "      <td>29.126749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>233.0</td>\n",
       "      <td>28.703863</td>\n",
       "      <td>33.165115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175.0</td>\n",
       "      <td>30.394286</td>\n",
       "      <td>41.814849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>213.0</td>\n",
       "      <td>36.413146</td>\n",
       "      <td>55.160899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>371.0</td>\n",
       "      <td>28.417790</td>\n",
       "      <td>43.926666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5637.0</td>\n",
       "      <td>33.625155</td>\n",
       "      <td>85.486574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>503.0</td>\n",
       "      <td>23.149105</td>\n",
       "      <td>38.298311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201.0</td>\n",
       "      <td>28.303483</td>\n",
       "      <td>46.472061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>189.0</td>\n",
       "      <td>35.370370</td>\n",
       "      <td>43.143876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std  min  25%   50%   75%     max\n",
       "month                                                            \n",
       "1       232.0  35.155172  46.704673  0.0  7.0  17.5  41.0   302.0\n",
       "2       211.0  35.037915  55.930386  0.0  7.0  14.0  35.5   442.0\n",
       "3       221.0  28.384615  40.605771  0.0  7.0  14.0  33.0   342.0\n",
       "4       227.0  23.092511  29.126749  0.0  5.0  12.0  30.0   196.0\n",
       "5       233.0  28.703863  33.165115  0.0  7.0  15.0  37.0   159.0\n",
       "6       175.0  30.394286  41.814849  0.0  7.0  15.0  34.5   332.0\n",
       "7       213.0  36.413146  55.160899  1.0  7.0  16.0  44.0   368.0\n",
       "8       371.0  28.417790  43.926666  0.0  5.0  12.0  32.0   387.0\n",
       "9      5637.0  33.625155  85.486574  0.0  6.0  14.0  35.0  3138.0\n",
       "10      503.0  23.149105  38.298311  0.0  4.0  11.0  25.0   361.0\n",
       "11      201.0  28.303483  46.472061  1.0  7.0  15.0  35.0   561.0\n",
       "12      189.0  35.370370  43.143876  1.0  8.0  19.0  49.0   235.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('month')['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e85c7d8-2b8a-4ac9-a102-a1f27dd5c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_gt_median</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>FIND YOUR BIG THREE TWIN (ORGANISED EDITION)</td>\n",
       "      <td>READ:INSTRUCTIONS:I HAVE WRITTEN EVERY SUN AND...</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>1019</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>FIND YOUR BIG THREE TWIN (ORGANISED EDITION)</td>\n",
       "      <td>READ:\\nINSTRUCTIONS:\\n\\nI HAVE WRITTEN EVERY S...</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>1030</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>3138</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time                                         title  \\\n",
       "1811 2020-09-10  FIND YOUR BIG THREE TWIN (ORGANISED EDITION)   \n",
       "4797 2021-09-11  FIND YOUR BIG THREE TWIN (ORGANISED EDITION)   \n",
       "\n",
       "                                              body-text  title-cc  title-wc  \\\n",
       "1811  READ:INSTRUCTIONS:I HAVE WRITTEN EVERY SUN AND...        44         7   \n",
       "4797  READ:\\nINSTRUCTIONS:\\n\\nI HAVE WRITTEN EVERY S...        44         7   \n",
       "\n",
       "      body-cc  body-wc  media  comments  comments_gt_median  day  month  \\\n",
       "1811     1019      175      0      3100                   1    3      9   \n",
       "4797     1030      175      0      3138                   1    5      9   \n",
       "\n",
       "      weekend  \n",
       "1811        0  \n",
       "4797        0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['comments'] > 3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d015-1bdf-4ce4-81df-095311174c03",
   "metadata": {},
   "source": [
    "**NOTES** Months pretty stable, except there is one post in september 2021 that has over 3000 comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f37db-a647-4be2-9027-eacb8831a437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
