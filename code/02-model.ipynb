{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e635b4-7f51-4771-b503-3991eb4065e4",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Part 2: Modeling\n",
    "\n",
    "Model data for fun and profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99841833-554e-40b2-b472-4a57b0cf38be",
   "metadata": {},
   "source": [
    "### 0. Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50529b0d-9aea-49b6-9429-7f6b910de60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# pipelines, gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# nltk - for stopwords and stemming\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# custom\n",
    "import ipynb_utils as ipyutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b96d9fe-61c8-4b4e-8909-50c00610ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_json('../data/scrapes-clean.json', orient='index')\n",
    "\n",
    "# convert time to datetime object\n",
    "df['time'] = pd.to_datetime(df['time'], format=ipyutils.DATE_FMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6020c18d-2747-4806-bdfd-94cdda105993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body-text</th>\n",
       "      <th>title-cc</th>\n",
       "      <th>title-wc</th>\n",
       "      <th>body-cc</th>\n",
       "      <th>body-wc</th>\n",
       "      <th>media</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Newbie questions about ascendants and borders</td>\n",
       "      <td>I'm new to actually learning astrology, not ju...</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>Astrology and cognitive dissonance</td>\n",
       "      <td>Open to anyone who wouldn't mind sharing a rec...</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>what do y’all think of persona charts?</td>\n",
       "      <td>I feel a bit skeptical of them, since I feel l...</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>180</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>RESOURCE REQUEST: Videos (or articles) with ti...</td>\n",
       "      <td>I think my problem is that I don’t know the pr...</td>\n",
       "      <td>160</td>\n",
       "      <td>24</td>\n",
       "      <td>597</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>people who have had saturn transit their 10th,...</td>\n",
       "      <td>How did it affect your career? Did it impact y...</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>116</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title  \\\n",
       "0 2022-09-05      Newbie questions about ascendants and borders   \n",
       "2 2022-09-05                 Astrology and cognitive dissonance   \n",
       "3 2022-09-05             what do y’all think of persona charts?   \n",
       "4 2022-09-05  RESOURCE REQUEST: Videos (or articles) with ti...   \n",
       "5 2022-09-05  people who have had saturn transit their 10th,...   \n",
       "\n",
       "                                           body-text  title-cc  title-wc  \\\n",
       "0  I'm new to actually learning astrology, not ju...        45         6   \n",
       "2  Open to anyone who wouldn't mind sharing a rec...        34         4   \n",
       "3  I feel a bit skeptical of them, since I feel l...        38         7   \n",
       "4  I think my problem is that I don’t know the pr...       160        24   \n",
       "5  How did it affect your career? Did it impact y...        64        12   \n",
       "\n",
       "   body-cc  body-wc  media  comments  \n",
       "0      601      107      0         0  \n",
       "2      323       49      0         1  \n",
       "3      180       29      0         0  \n",
       "4      597       94      0         2  \n",
       "5      116       22      0        11  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all looks good...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68d3abe-7eda-4afc-aad8-c0fb1bdc3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         datetime64[ns]\n",
       "title                object\n",
       "body-text            object\n",
       "title-cc              int64\n",
       "title-wc              int64\n",
       "body-cc               int64\n",
       "body-wc               int64\n",
       "media                 int64\n",
       "comments              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and that the right datatypes are showing\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f070fd-61b1-4867-9525-09cf7396a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8413, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ea98a-32ed-4d4f-9d19-1524ee3836ae",
   "metadata": {},
   "source": [
    "### 0.5. Problem Statement\n",
    "\n",
    "What characteristics of a post on Reddit are most predictive of the overall interaction on a thread (as measured by number of comments)?\n",
    "\n",
    "Model will attempt to predict whether or not a given Reddit post will have above or below the median number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa388c-79f9-48bd-bb58-3b48e0aa7a62",
   "metadata": {},
   "source": [
    "### 1. Generate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50e06b6-908f-48bf-9da0-45e59538381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median comments\n",
    "median = np.median(df['comments'])\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb5882c-281f-4590-87a3-9d02cd06c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4271\n",
       "1    4142\n",
       "Name: comments_gt_median, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target column\n",
    "df['comments_gt_median'] = (df['comments'] > median).astype(int)\n",
    "df['comments_gt_median'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60706e98-2d48-4241-8b04-7b9945ab2a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.507667\n",
       "1    0.492333\n",
       "Name: comments_gt_median, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments_gt_median'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4b475-21fc-492b-8192-0e8fb9e2e5e9",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "Baseline is just about **50%**, as it should be since we are using median as split for determining high vs. low engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff91f72-3c70-4c85-a04c-404b0cf25365",
   "metadata": {},
   "source": [
    "### 1a. Split Time Column\n",
    "\n",
    "Might want to check by month or day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff00a030-b964-4f6f-86b7-2dc6be418e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['time'].apply(ipyutils.get_day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113fea0d-7c35-450b-9f5c-380b93291297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['time'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59e1340-568b-48d4-a6e8-30601e41c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month\n",
       "0    0      9\n",
       "2    0      9\n",
       "3    0      9\n",
       "4    0      9\n",
       "5    0      9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['day','month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec924ed-83a8-4c00-9193-0a2add1b6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "10    0\n",
       "11    0\n",
       "Name: weekend, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekend'] = (df['day'] > 5).astype(int)\n",
    "df['weekend'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cb886e1-140e-4947-8eb2-2affc76f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this just to be safe as I've gotten some weird row mismatches\n",
    "# later on and not sure exactly why\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421586c-0e19-4b86-8f58-b8ebdd3d751c",
   "metadata": {},
   "source": [
    "### 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ff9ecee-a22a-42de-bba7-c90e944b8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5889, 11), (2524, 11), (5889,), (2524,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = 'comments_gt_median'\n",
    "cols_to_drop = ['time'] # don't need this any more\n",
    "X = df.drop(columns=[col_target]+cols_to_drop)\n",
    "y = df[col_target]\n",
    "\n",
    "# split to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20637c-93dd-4710-aa9f-36f5ab8d8867",
   "metadata": {},
   "source": [
    "### 3. Count Vectorize Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705ff509-48f0-40e7-b192-8caa78ecb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for testing stemming - taken from course \n",
    "# materials 33-nlp-ii\n",
    "def stem_tokenizer(doc):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "def lemma_tokenizer(doc):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "# I tried these on the CountVectorizer and they result in some bogus matches\n",
    "# (like whitespace and punctuation). I don't have time to really look into this,\n",
    "# and the scores from my tests on these were not very different from not using\n",
    "# them, so I'm not going to use them this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f5ffad-24f9-4d37-8311-791f9d141dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5889, 6847),\n",
       " (2524, 6847),\n",
       " (5889, 60605),\n",
       " (2524, 60605),\n",
       " (5889, 65666),\n",
       " (2524, 65666))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count vectorize tables\n",
    "cv_params = {\n",
    "    'token_pattern': ipyutils.PAT_TOKEN,\n",
    "    'min_df': 2,\n",
    "    'stop_words': stopwords.words('english'),\n",
    "    'ngram_range': (1,2),\n",
    "    'tokenizer': None # tried stem_tokenizer, lemma_tokenizer\n",
    "}\n",
    "cv_title = CountVectorizer(**cv_params)\n",
    "cv_body = CountVectorizer(**cv_params)\n",
    "cv_alltext = CountVectorizer(**cv_params)\n",
    "\n",
    "# title\n",
    "train_title_cv = cv_title.fit_transform(X_train['title'])\n",
    "test_title_cv = cv_title.transform(X_test['title'])\n",
    "\n",
    "# body\n",
    "train_body_cv = cv_body.fit_transform(X_train['body-text'])\n",
    "test_body_cv = cv_body.transform(X_test['body-text'])\n",
    "\n",
    "# title + body\n",
    "train_alltext_cv = cv_alltext.fit_transform(X_train['title'] + ' ' + X_train['body-text'])\n",
    "test_alltext_cv = cv_alltext.transform(X_test['title'] + ' ' + X_test['body-text'])\n",
    "\n",
    "(train_title_cv.shape, test_title_cv.shape, \n",
    "train_body_cv.shape, test_body_cv.shape,\n",
    "train_alltext_cv.shape, test_alltext_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f18623-b41f-4f80-ae70-412ddd6937db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zero degrees', 'zodiac', 'zodiac beauty', 'zodiac collection',\n",
       "       'zodiac compatibility', 'zodiac girls', 'zodiac illustration',\n",
       "       'zodiac series', 'zodiac sign', 'zodiac signs', 'zodiac system',\n",
       "       'zodiac très', 'zodiac war', 'zodiac witch', 'zodiacal',\n",
       "       'zodiacal releasing', 'zodiacs', 'zodiacsigns', 'zodiaz',\n",
       "       'zodiaz sign'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_title.get_feature_names_out()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ffc7bb6-528e-4859-acb1-277e3d374639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zodiac think', 'zodiac time', 'zodiac très', 'zodiac turn',\n",
       "       'zodiac twelve', 'zodiac war', 'zodiac wheel', 'zodiac whose',\n",
       "       'zodiac witch', 'zodiacal', 'zodiacal releasing', 'zodiacal sign',\n",
       "       'zodiacal signs', 'zodiacs', 'zodiacs good', 'zodiacs planets',\n",
       "       'zodiacs simply', 'zodiacs twelve', 'zodiacs uses', 'zodiacsigns',\n",
       "       'zodiacwar', 'zodiart', 'zodiaz', 'zodiaz sign', 'zone',\n",
       "       'zone pre', 'zones', 'zooey', 'zoom', 'zoom signal', 'zoomer',\n",
       "       'zoomer gay', 'zoomers', 'zoomers lgbtq', 'zoomers well',\n",
       "       'zuckerberg', '𝐅𝐮𝐥𝐥', '𝐅𝐮𝐥𝐥 𝐌𝐨𝐨𝐧', '𝐌𝐨𝐨𝐧', '𝟐𝟔'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_alltext.get_feature_names_out()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f81ff7-f431-4ce8-9fb4-f9f1e0b221bc",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0239a9a2-1ab5-402e-bcae-3ae8cfb40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rfc = RandomForestClassifier()\n",
    "gs_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [4, 5],\n",
    "    'min_impurity_decrease': [0.0001, 0.001],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "# use gridsearch this time only to check best model params (takes a long time)\n",
    "gs = GridSearchCV(title_rfc, gs_params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b9ecc2a-0156-4318-a05c-d72fd957ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Model Train Score (best): 0.7408728137204958\n",
      "Model Test Score (best): 0.6596671949286846\n",
      "Model Best Estimator: RandomForestClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on titles only\n",
    "gs.fit(train_title_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(gs, \n",
    "                            (train_title_cv, y_train), \n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d54fc9a9-2705-40eb-9203-2332dfd49306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_impurity_decrease': 0.0001,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8fc8313-7ea8-4491-9818-596d9d2a9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params to use for later models\n",
    "rfc_params = gs.best_params_\n",
    "# {\n",
    "#     'min_impurity_decrease': 0.0001,\n",
    "#     'min_samples_leaf': 5,\n",
    "#     'min_samples_split': 4,\n",
    "#     'n_estimators': 300,\n",
    "#     'n_jobs': -1,\n",
    "#     'random_state': 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b123faac-bb0d-4e5a-8320-02e0cf449423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.7532688062489387\n",
      "Model Test Score (best): 0.6497622820919176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on body text only - use same best params from gridsearch\n",
    "body_rfc = RandomForestClassifier(**rfc_params)\n",
    "body_rfc.fit(train_body_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(body_rfc, \n",
    "                            (train_body_cv, y_train), \n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cd63ce8-a88c-4183-a000-6f53caa57c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Train Score (best): 0.8030225844795381\n",
      "Model Test Score (best): 0.6834389857369255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model on all text\n",
    "alltext_rfc = RandomForestClassifier(**rfc_params)\n",
    "alltext_rfc.fit(train_alltext_cv, y_train)\n",
    "print()\n",
    "print(ipyutils.score_report(alltext_rfc, \n",
    "                            (train_alltext_cv, y_train), \n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6edc7-132a-4475-bb2d-a00a84a517d2",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2179dc31-60cf-4e36-bbce-360d51481ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.67      0.65      0.66      1281\n",
      "         low       0.65      0.67      0.66      1243\n",
      "\n",
      "    accuracy                           0.66      2524\n",
      "   macro avg       0.66      0.66      0.66      2524\n",
      "weighted avg       0.66      0.66      0.66      2524\n",
      "\n",
      "True Positives: 828\n",
      "True Negatives: 837\n",
      "False Positives: 444\n",
      "False Negatives: 415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# title words\n",
    "print(ipyutils.metrics_report(gs.best_estimator_, y_test, test_title_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed8e8a93-fe21-46be-89e5-0b812b2ff8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.68      0.58      0.63      1281\n",
      "         low       0.63      0.72      0.67      1243\n",
      "\n",
      "    accuracy                           0.65      2524\n",
      "   macro avg       0.65      0.65      0.65      2524\n",
      "weighted avg       0.65      0.65      0.65      2524\n",
      "\n",
      "True Positives: 892\n",
      "True Negatives: 748\n",
      "False Positives: 533\n",
      "False Negatives: 351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# body words\n",
    "print(ipyutils.metrics_report(body_rfc, y_test, test_body_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14307311-65b9-4473-b0d4-d5fd5b03a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.70      0.66      0.68      1281\n",
      "         low       0.67      0.71      0.69      1243\n",
      "\n",
      "    accuracy                           0.68      2524\n",
      "   macro avg       0.68      0.68      0.68      2524\n",
      "weighted avg       0.68      0.68      0.68      2524\n",
      "\n",
      "True Positives: 877\n",
      "True Negatives: 848\n",
      "False Positives: 433\n",
      "False Negatives: 366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all words\n",
    "print(ipyutils.metrics_report(alltext_rfc, y_test, test_alltext_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40edadf-bd04-47eb-966b-d9309c265025",
   "metadata": {},
   "source": [
    "#### Analysis of Random Forest Classifier Score\n",
    "\n",
    "Perhaps unsurprisingly, analyzing on the full text (body plus title) gave better prediction accuracy. However, for purposes of the problem statement, the title and body are possibly best kept separate, as reddit does not diplay the full body text by default, and searches only display titles.\n",
    "\n",
    "Accuracy is better than baseline, but not by a huge amount. Gridsearch does not reveal too much about the possible model parameters - it just tells me that the more specific model scores better.\n",
    "\n",
    "The model is overfit (which is probably to be expected from a decision-tree-based model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99bf60-d9a8-44e4-8cb7-d15db687edda",
   "metadata": {},
   "source": [
    "#### Exploration of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a4c66b7-d1bd-4a8b-943e-b373daa88f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title exploration - what words were best predictors?\n",
    "# get predictions\n",
    "preds_test = gs.best_estimator_.predict(test_title_cv)\n",
    "Xdf = pd.DataFrame(test_title_cv.A, \n",
    "                   columns=cv_title.get_feature_names_out(),\n",
    "                   index=y_test.index)\n",
    "# get filter for correct predictions (use index to label)\n",
    "preds_correct_filt = (preds_test == y_test)\n",
    "preds_tp_filt = (preds_test == y_test) & (y_test == 1)\n",
    "preds_tn_filt = (preds_test == y_test) & (y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e7a766d-d6ec-4bb5-9320-f1e92ae4e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>223</td>\n",
       "      <td>156</td>\n",
       "      <td>67</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astrology</th>\n",
       "      <td>328</td>\n",
       "      <td>208</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saturn</th>\n",
       "      <td>143</td>\n",
       "      <td>106</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moon</th>\n",
       "      <td>232</td>\n",
       "      <td>150</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chart</th>\n",
       "      <td>303</td>\n",
       "      <td>182</td>\n",
       "      <td>121</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signs</th>\n",
       "      <td>145</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placements</th>\n",
       "      <td>115</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>229</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspects</th>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total  correct  incorrect  diff\n",
       "sign          223      156         67    89\n",
       "astrology     328      208        120    88\n",
       "saturn        143      106         37    69\n",
       "moon          232      150         82    68\n",
       "chart         303      182        121    61\n",
       "signs         145       99         46    53\n",
       "placements    115       82         33    49\n",
       "full           70       56         14    42\n",
       "house         229      135         94    41\n",
       "aspects        96       68         28    40"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word counts for correct and incorrect predictions\n",
    "wordcounts = pd.DataFrame()\n",
    "wordcounts['total'] = Xdf.sum()\n",
    "wordcounts['correct'] = Xdf.loc[preds_correct_filt].sum()\n",
    "wordcounts['incorrect'] = Xdf[~preds_correct_filt].sum()\n",
    "\n",
    "# get difference of correct and incorrect predictions per word\n",
    "# This shows what words had more correct over incorrect predictions\n",
    "wordcounts['diff'] = (wordcounts['correct'] - wordcounts['incorrect'])\n",
    "\n",
    "wordcounts.sort_values(by='diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181b142-f8ad-469d-9c25-9e1b4553a9b3",
   "metadata": {},
   "source": [
    "### 3a. ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "425ad43f-4764-4b0f-9b4a-9119a9bd68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Model Train Score (best): 0.7702898550724637\n",
      "Model Test Score (best): 0.6233108108108109\n",
      "Model Best Estimator: ExtraTreesClassifier(min_impurity_decrease=0.0001, min_samples_leaf=4,\n",
      "                     min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
      "                     random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_etc = ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
    "# use same gs_params from random forest\n",
    "title_etc_gs = GridSearchCV(title_etc, gs_params, verbose=1, n_jobs=-1)\n",
    "title_etc_gs.fit(train_title_cv, y_train)\n",
    "print(ipyutils.score_report(title_etc_gs,\n",
    "                            (train_title_cv, y_train),\n",
    "                            (test_title_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7dede69f-bccc-48dd-9e35-2005909d76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_params = {\n",
    "    'min_impurity_decrease': 0.0001,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 200,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99b33d6a-50dd-4417-a58f-d019032a12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.7934782608695652\n",
      "Model Test Score (best): 0.6672297297297297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_etc = ExtraTreesClassifier(**etc_params)\n",
    "body_etc.fit(train_body_cv, y_train)\n",
    "print(ipyutils.score_report(body_etc,\n",
    "                            (train_body_cv, y_train),\n",
    "                            (test_body_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f93d52f9-84d7-4018-adeb-e1e05c4fbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score (best): 0.8695652173913043\n",
      "Model Test Score (best): 0.6722972972972973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alltext_etc = ExtraTreesClassifier(**etc_params)\n",
    "alltext_etc.fit(train_alltext_cv, y_train)\n",
    "print(ipyutils.score_report(alltext_etc,\n",
    "                            (train_alltext_cv, y_train),\n",
    "                            (test_alltext_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1a46-a11f-443c-a1df-9ce896ce34ad",
   "metadata": {},
   "source": [
    "#### Analysis of Extra Trees Classifier Score\n",
    "\n",
    "ExtraTrees did not fare any better than Random Forest on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42df3-ce1d-4a10-ba00-c8c6879bcc0b",
   "metadata": {},
   "source": [
    "### 4. Other Classifiers (Quick Comparisons)\n",
    "\n",
    "I am testing a number of other classifiers on the alltext set to see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcd52c68-5cc8-4177-bdcd-bda851966f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9884057971014493, 0.6638513513513513)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost\n",
    "rfc = RandomForestClassifier(**rfc_params)\n",
    "ada = AdaBoostClassifier(rfc, random_state=1)\n",
    "ada.fit(train_alltext_cv, y_train)\n",
    "ada.score(train_alltext_cv, y_train), ada.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d0ae404-9996-4796-8c15-3ea2b9eae457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6659420289855073, 0.5168918918918919)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbors\n",
    "knc = KNeighborsClassifier(5)\n",
    "knc.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c1be38a-e5ea-425c-b15d-ca9fb6ab357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6659420289855073, 0.5168918918918919)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_alltext_cv, y_train)\n",
    "knc.score(train_alltext_cv, y_train), knc.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2deab815-a991-4d89-b283-a5a441273165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8485507246376811, 0.6706081081081081)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_alltext_cv, y_train)\n",
    "mnb.score(train_alltext_cv, y_train), mnb.score(test_alltext_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a3678-2005-4494-9218-147afcbdb87e",
   "metadata": {},
   "source": [
    "#### Analysis of Other Classifiers on Word Vectors\n",
    "\n",
    "Naive Bayes performed best, with AdaBoost second. AdaBoost was severely overfit. Naive Bayes was a bit more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b24f9-6edb-4c2d-9e81-da91c969002a",
   "metadata": {},
   "source": [
    "### 4a. Other Features with Various Classifiers\n",
    "\n",
    "There are a few other features I'd like to explore (word/character counts, for example).\n",
    "\n",
    "Date/time features might not be appropriate here due to how Reddit works and the scraping process. Reddit no longer allows search by date, so I cannot get consecutive posts over time, and I am therefore trying to get as many posts I can via searches for words. Therefore, the post distribution over time that I get from my scrapes may not be the same as the actual post distribution over time, and there is no way to verify this with my current scraping process. If I have enough posts from different dates I could possibly consider distribution requirement satisfied, but I'm a bit skeptical now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebaa4027-9d3e-480f-9a87-15f22ffd402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'title', 'body-text', 'title-cc', 'title-wc', 'body-cc',\n",
       "       'body-wc', 'media', 'comments', 'comments_gt_median', 'day', 'month',\n",
       "       'weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a718e-2a72-4892-acfc-5d7e505ba219",
   "metadata": {},
   "source": [
    "#### Word- and Character-counts and Media Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7209ab69-89ce-422d-8659-6a537d08ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to test all of the following feature combinations just to see if\n",
    "# they show any major differences\n",
    "col_opts = [\n",
    "    ['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc'],\n",
    "    ['media'],\n",
    "    ['title-cc', 'title-wc'],\n",
    "    ['body-cc', 'body-wc'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc'],\n",
    "    ['day'],\n",
    "    ['month'],\n",
    "    ['day', 'month'],\n",
    "    ['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b536dcd9-e057-46b3-b2f6-5f43e5983b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain: 0.8028985507246377\n",
      "\ttest: 0.6351351351351351\n",
      "['media']\n",
      "\ttrain: 0.5434782608695652\n",
      "\ttest: 0.543918918918919\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain: 0.6659420289855073\n",
      "\ttest: 0.5337837837837838\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain: 0.6855072463768116\n",
      "\ttest: 0.5929054054054054\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain: 0.8079710144927537\n",
      "\ttest: 0.6131756756756757\n",
      "['day']\n",
      "\ttrain: 0.6181159420289855\n",
      "\ttest: 0.597972972972973\n",
      "['month']\n",
      "\ttrain: 0.6876811594202898\n",
      "\ttest: 0.7010135135135135\n",
      "['day', 'month']\n",
      "\ttrain: 0.6876811594202898\n",
      "\ttest: 0.7010135135135135\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain: 0.8028985507246377\n",
      "\ttest: 0.6452702702702703\n"
     ]
    }
   ],
   "source": [
    "# loop over each feature combination and run a model\n",
    "for opt in col_opts:\n",
    "    xrfc = RandomForestClassifier(**rfc_params)\n",
    "    xrfc.fit(X_train[opt], y_train)\n",
    "    print(f'{opt}\\n\\ttrain: {xrfc.score(X_train[opt], y_train)}'\\\n",
    "          + f'\\n\\ttest: {xrfc.score(X_test[opt], y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "991dcc41-103b-460b-9cc2-48e71dfccb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 1445) (592, 1445)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1444) (592, 1444)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1441) (592, 1441)\n",
      "(1380, 1442) (592, 1442)\n",
      "(1380, 1445) (592, 1445)\n"
     ]
    }
   ],
   "source": [
    "# now let's do the same but adding the Vectorized title\n",
    "\n",
    "# make vectorized title dataframes\n",
    "train_title_cv_df = ipyutils.df_from_cv(cv_title, train_title_cv, X_train.index)\n",
    "test_title_cv_df = ipyutils.df_from_cv(cv_title, test_title_cv, X_test.index)\n",
    "\n",
    "# concat all column combos to vectorized title dataframes\n",
    "combo_dfs = list()\n",
    "for opt in col_opts:\n",
    "    # 0 is train, 1 is test\n",
    "    combo_dfs.append((ipyutils.easy_concat(X_train[opt], train_title_cv_df),\n",
    "                      ipyutils.easy_concat(X_test[opt], test_title_cv_df)))\n",
    "\n",
    "# check for integrity\n",
    "for cdf in combo_dfs:\n",
    "    print(cdf[0].shape, cdf[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "941acabc-f0f9-4fc1-9da7-bed61b138cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media', 'title-cc', 'body-cc', 'title-wc', 'body-wc']\n",
      "\ttrain:0.7028985507246377\n",
      "\ttest:0.643581081081081\n",
      "['media']\n",
      "\ttrain:0.6992753623188406\n",
      "\ttest:0.6131756756756757\n",
      "['title-cc', 'title-wc']\n",
      "\ttrain:0.6905797101449276\n",
      "\ttest:0.6452702702702703\n",
      "['body-cc', 'body-wc']\n",
      "\ttrain:0.7057971014492753\n",
      "\ttest:0.6351351351351351\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc']\n",
      "\ttrain:0.7043478260869566\n",
      "\ttest:0.6469594594594594\n",
      "['day']\n",
      "\ttrain:0.7057971014492753\n",
      "\ttest:0.6402027027027027\n",
      "['month']\n",
      "\ttrain:0.7231884057971014\n",
      "\ttest:0.6976351351351351\n",
      "['day', 'month']\n",
      "\ttrain:0.7188405797101449\n",
      "\ttest:0.6942567567567568\n",
      "['title-cc', 'title-wc', 'body-cc', 'body-wc', 'day']\n",
      "\ttrain:0.7028985507246377\n",
      "\ttest:0.6672297297297297\n"
     ]
    }
   ],
   "source": [
    "# run a model on each combo\n",
    "for ix, cdf in enumerate(combo_dfs):\n",
    "    opt = col_opts[ix]\n",
    "    xrfc.fit(cdf[0], y_train)\n",
    "    print(f'{opt}\\n\\ttrain:{xrfc.score(cdf[0], y_train)}\\n'\\\n",
    "          + f'\\ttest:{xrfc.score(cdf[1], y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872cb055-8a93-4e1d-8e3e-85dfc1622ac9",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "From what I've seen so far, adding vectorized text data seems to even out the model a bit, with less overfitting than when using just word- and character-count features.\n",
    "\n",
    "**However...** no model seems to be able to reach 70%+ accuracy. We are stuck in the 60% zone.\n",
    "\n",
    "I'm doing all of this right now on a very small subset of data so all subject to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba82f31-612b-4161-ad87-a6430da8a3bc",
   "metadata": {},
   "source": [
    "#### Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f921e5d3-09c2-4a2d-8c1d-f44b4d9c165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484.0</td>\n",
       "      <td>43.442149</td>\n",
       "      <td>40.767618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>29.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>47.452381</td>\n",
       "      <td>75.077262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.75</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>28.829268</td>\n",
       "      <td>38.206191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.25</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>564.0</td>\n",
       "      <td>80.189716</td>\n",
       "      <td>175.136134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307.0</td>\n",
       "      <td>35.684039</td>\n",
       "      <td>48.040096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.0</td>\n",
       "      <td>27.331658</td>\n",
       "      <td>37.591512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>212.0</td>\n",
       "      <td>52.485849</td>\n",
       "      <td>70.056475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count       mean         std  min    25%   50%    75%     max\n",
       "day                                                               \n",
       "0    484.0  43.442149   40.767618  0.0  14.75  29.0  61.00   255.0\n",
       "1     42.0  47.452381   75.077262  0.0   7.25  20.0  53.75   359.0\n",
       "2    164.0  28.829268   38.206191  0.0   6.00  14.0  31.25   224.0\n",
       "3    564.0  80.189716  175.136134  0.0  19.00  42.0  89.00  3100.0\n",
       "4    307.0  35.684039   48.040096  0.0  10.00  21.0  43.00   368.0\n",
       "5    199.0  27.331658   37.591512  0.0   4.50  13.0  34.00   207.0\n",
       "6    212.0  52.485849   70.056475  0.0   8.00  30.0  72.25   596.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('day')['comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bde61-66ab-4a60-abbd-2e3d7be01c9f",
   "metadata": {},
   "source": [
    "**NOTES** Thursday seems to be a hot day for comments, with a much higher mean, median, and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7324461-171a-4987-9641-180857654837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>97.888889</td>\n",
       "      <td>49.936070</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>139.00</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>159.250000</td>\n",
       "      <td>86.289794</td>\n",
       "      <td>47.0</td>\n",
       "      <td>118.75</td>\n",
       "      <td>141.0</td>\n",
       "      <td>182.00</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.0</td>\n",
       "      <td>23.722222</td>\n",
       "      <td>32.812362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>24.25</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159.0</td>\n",
       "      <td>24.981132</td>\n",
       "      <td>33.494468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.50</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>174.0</td>\n",
       "      <td>29.885057</td>\n",
       "      <td>33.677466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>15.5</td>\n",
       "      <td>37.00</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124.0</td>\n",
       "      <td>26.008065</td>\n",
       "      <td>29.621322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>254.0</td>\n",
       "      <td>34.818898</td>\n",
       "      <td>56.249292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.50</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>188.0</td>\n",
       "      <td>26.675532</td>\n",
       "      <td>42.299619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.25</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>927.0</td>\n",
       "      <td>73.365696</td>\n",
       "      <td>140.831429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>51.545455</td>\n",
       "      <td>36.835753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>54.0</td>\n",
       "      <td>84.50</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>84.013888</td>\n",
       "      <td>43.0</td>\n",
       "      <td>70.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>153.00</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>56.484300</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.50</td>\n",
       "      <td>87.0</td>\n",
       "      <td>115.50</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count        mean         std   min     25%    50%     75%     max\n",
       "month                                                                    \n",
       "1        9.0   97.888889   49.936070  26.0   64.00   80.0  139.00   166.0\n",
       "2        8.0  159.250000   86.289794  47.0  118.75  141.0  182.00   330.0\n",
       "3      108.0   23.722222   32.812362   0.0    6.00   11.5   24.25   198.0\n",
       "4      159.0   24.981132   33.494468   0.0    4.00   12.0   31.50   196.0\n",
       "5      174.0   29.885057   33.677466   0.0    7.25   15.5   37.00   159.0\n",
       "6      124.0   26.008065   29.621322   1.0    7.00   15.0   30.25   152.0\n",
       "7      254.0   34.818898   56.249292   0.0    6.00   14.0   37.50   390.0\n",
       "8      188.0   26.675532   42.299619   0.0    5.00   11.0   29.25   359.0\n",
       "9      927.0   73.365696  140.831429   2.0   23.00   44.0   85.00  3100.0\n",
       "10      11.0   51.545455   36.835753   0.0   14.50   54.0   84.50    99.0\n",
       "11       3.0  116.333333   84.013888  43.0   70.50   98.0  153.00   208.0\n",
       "12       7.0   85.142857   56.484300  22.0   40.50   87.0  115.50   175.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('month')['comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d015-1bdf-4ce4-81df-095311174c03",
   "metadata": {},
   "source": [
    "**NOTES** not enough month data right now, with very low counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddcbe7-769d-4bfa-a242-9ad0fcaa4bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
